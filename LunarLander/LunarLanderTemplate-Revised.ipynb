{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "764fe135-c09e-9769-5794-500867154d93",
    "_uuid": "de6a1e240579227a8dd89aa213f6acfcf7d988b0"
   },
   "source": [
    "# Lunar Lander - Revised\n",
    "\n",
    "Inspiration for this notebook comes from this [Keras blog post](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), the [VGG ConvNet paper](https://arxiv.org/pdf/1409.1556.pdf), and the [OpenAI Gym](https://gym.openai.com/). \n",
    "\n",
    "Train a model to play the Lunar Lander game from OpenAI gym using a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d458c15-e131-f3c4-f756-843d6454bb37",
    "_uuid": "76c68c2752f5c4a44660ccadda2168aaeca3930d"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04681981-55ac-7820-a0ae-38f98c851c39",
    "_uuid": "1d1d3e8597d7e7805843de17d8514854ea5deaa3"
   },
   "source": [
    "## Preparing the Data\n",
    "Load the raw image dataset and pre-process it. Divide this into train and test splits. Balance the training split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads a set of images and resizes each image to 64x64 and coverts to black and white. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "663d335e-1b84-a8cb-19ee-8f04839cf4e5",
    "_uuid": "16ddc310f7e96e68f1a5cb8ef796be3afdbb33f8"
   },
   "outputs": [],
   "source": [
    "# Set up some parmaeters for data loading\n",
    "TRAIN_DIR = './data/'\n",
    "sample_rate = 0.1\n",
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 1\n",
    "\n",
    "# generate filenames from the data folder and do sampling\n",
    "image_filenames = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if not i.startswith('.')] # use this for full dataset\n",
    "image_filenames = random.sample(image_filenames, int(len(image_filenames)*sample_rate))\n",
    "\n",
    "# Create a data array for image data\n",
    "count = len(image_filenames)\n",
    "data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.float)\n",
    "\n",
    "# Iterate throuigh the filenames and for each one load the image, resize and normalise\n",
    "for i, image_file in enumerate(image_filenames):\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)        \n",
    "    data[i] = image\n",
    "    data[i] = data[i]/255\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n",
    "\n",
    "print(\"Train shape: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed0fc95a-53bc-3517-245d-cf1f5122bc2d",
    "_uuid": "2f79703b02d0fee947f5615e09d1717e6ba250fd"
   },
   "source": [
    "### Generating the Labels\n",
    "\n",
    "We're dealing with a multi-class classification problem here - (0) no action, (1) left, (2) up, and (3) right. The lables can be created by looping over the file names in the train directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0f2fbf6-8d78-7d42-6579-5486a36c1e60",
    "_uuid": "ba1fa53e4ef436c3e26d0ef7b8d3f327db9ae6c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the lables from the last characters in the filename\n",
    "labels = []\n",
    "for i in image_filenames:\n",
    "    l = i[-6:-5]\n",
    "    labels.append(int(l))\n",
    "        \n",
    "# Count the number of clases\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "# convert to binary encoded labels\n",
    "labels_wide = keras.utils.to_categorical(labels, num_classes)\n",
    "\n",
    "# Plot a bar plot of the \n",
    "sns.countplot(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bb0bd2a-0512-aa72-c628-5b6ac946d97c",
    "_uuid": "eb663ef4c6599e3353c902a0b891c8d12327a8ea"
   },
   "source": [
    "### Show some screens\n",
    "Print a few screens with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    idx = random.randint(0, len(labels))\n",
    "    print(labels[idx])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(data[idx][0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the dataset for evaluation\n",
    "Split the data into a training and test partition so we can evaluate at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(data, labels, random_state=0, test_size = 0.2, train_size = 0.8)\n",
    "train_labels_wide = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels_wide = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply under sampling to balance the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the random under-sampling\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "train_rus, train_labels_rus, idx_resampled = rus.fit_sample(train.reshape(len(train), ROWS*COLS*CHANNELS), train_labels)\n",
    "train_rus, train_labels_rus = shuffle(train_rus, train_labels_rus)\n",
    "train_rus = train_rus.reshape(len(train_rus), CHANNELS,ROWS, COLS)\n",
    "sns.countplot(train_labels_rus)\n",
    "train_labels_rus_wide = keras.utils.to_categorical(train_labels_rus, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bb0bd2a-0512-aa72-c628-5b6ac946d97c",
    "_uuid": "eb663ef4c6599e3353c902a0b891c8d12327a8ea"
   },
   "source": [
    "### Show some screens\n",
    "Print a few screens with their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    idx = random.randint(0, len(labels))\n",
    "    print(labels[idx])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(data[idx][0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    idx = random.randint(0, len(train_labels))\n",
    "    print(train_labels[idx])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(train[idx][0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    idx = random.randint(0, len(train_labels_rus))\n",
    "    print(train_labels_rus[idx])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(train_rus[idx][0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    idx = random.randint(0, len(test_labels))\n",
    "    print(test_labels[idx])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(test[idx][0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51e403b6-bcfc-b4fa-3770-9850cc86bae3",
    "_uuid": "16d4d2fe110a55d4cfe610cae4199f788b288d56"
   },
   "source": [
    "## LunarLanderNet\n",
    "\n",
    "A simple convolutional network to control the lander."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c477612-41d3-3112-5176-3c4ad9633080",
    "_uuid": "f316f98f6d395fe3898e7f0465e21cd8e7562b21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b7fbf156-2268-62ce-5fed-52a09af5e6f7",
    "_uuid": "c73a1d3f6b651c5897598e97019ea08a2e9d3d88"
   },
   "source": [
    "### Train\n",
    "Train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca613169-4b41-e9d5-27c7-6629f8e035c8",
    "_uuid": "28050bad88268405c6bbfcd42095a75bb53cc847"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of the loss as the module was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6266d01c-9d4c-a1dc-8cb9-ce7b3107b536",
    "_uuid": "38c7d51ca9ac5cd650f9f74e724017d0dc792449"
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "Use the test dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred = model.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist A Model\n",
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"player.mod\"\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"player.mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "# import plotly.plotly as py\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn import neural_network\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"state_vectors_2018-04-09-18-25-26.csv\", encoding = \"ISO-8859-1\")\n",
    "dataset = dataset.sample(frac=data_sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>vel_x</th>\n",
       "      <th>vel_y</th>\n",
       "      <th>ship_lander_angle</th>\n",
       "      <th>ship_lander_angular_vel</th>\n",
       "      <th>leg_1_ground_contact</th>\n",
       "      <th>leg_2_ground_contact</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91909</th>\n",
       "      <td>100</td>\n",
       "      <td>0.301275</td>\n",
       "      <td>0.289254</td>\n",
       "      <td>-0.262984</td>\n",
       "      <td>-0.217840</td>\n",
       "      <td>0.214712</td>\n",
       "      <td>-0.138139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183534</th>\n",
       "      <td>101</td>\n",
       "      <td>-0.119526</td>\n",
       "      <td>0.212999</td>\n",
       "      <td>0.236280</td>\n",
       "      <td>-0.282612</td>\n",
       "      <td>-0.086865</td>\n",
       "      <td>0.095317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236887</th>\n",
       "      <td>93</td>\n",
       "      <td>-0.016992</td>\n",
       "      <td>0.254888</td>\n",
       "      <td>0.034831</td>\n",
       "      <td>-0.352161</td>\n",
       "      <td>-0.014658</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96540</th>\n",
       "      <td>178</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>-0.026431</td>\n",
       "      <td>-0.132349</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>-0.067712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103870</th>\n",
       "      <td>91</td>\n",
       "      <td>-0.316885</td>\n",
       "      <td>0.293784</td>\n",
       "      <td>0.160349</td>\n",
       "      <td>-0.203210</td>\n",
       "      <td>-0.265415</td>\n",
       "      <td>0.101244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        step     pos_x     pos_y     vel_x     vel_y  ship_lander_angle  \\\n",
       "91909    100  0.301275  0.289254 -0.262984 -0.217840           0.214712   \n",
       "183534   101 -0.119526  0.212999  0.236280 -0.282612          -0.086865   \n",
       "236887    93 -0.016992  0.254888  0.034831 -0.352161          -0.014658   \n",
       "96540    178  0.029200  0.040598 -0.026431 -0.132349           0.152700   \n",
       "103870    91 -0.316885  0.293784  0.160349 -0.203210          -0.265415   \n",
       "\n",
       "        ship_lander_angular_vel  leg_1_ground_contact  leg_2_ground_contact  \\\n",
       "91909                 -0.138139                   0.0                   0.0   \n",
       "183534                 0.095317                   0.0                   0.0   \n",
       "236887                 0.022459                   0.0                   0.0   \n",
       "96540                 -0.067712                   0.0                   0.0   \n",
       "103870                 0.101244                   0.0                   0.0   \n",
       "\n",
       "        action  \n",
       "91909        0  \n",
       "183534       2  \n",
       "236887       2  \n",
       "96540        2  \n",
       "103870       0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:9]]\n",
    "Y = np.array(dataset[\"action\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37727"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37727"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>vel_x</th>\n",
       "      <th>vel_y</th>\n",
       "      <th>ship_lander_angle</th>\n",
       "      <th>ship_lander_angular_vel</th>\n",
       "      <th>leg_1_ground_contact</th>\n",
       "      <th>leg_2_ground_contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223515</th>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>4.711860e-04</td>\n",
       "      <td>-1.291953e-03</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.382630e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72164</th>\n",
       "      <td>-0.000756</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>9.414841e-04</td>\n",
       "      <td>-1.775322e-04</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.499266e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193363</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>3.357693e-04</td>\n",
       "      <td>-6.056298e-04</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>2.541082e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>1.294753e-04</td>\n",
       "      <td>-7.730860e-04</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-1.498529e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183186</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-5.025982e-07</td>\n",
       "      <td>-4.515411e-10</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>1.446544e-07</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pos_x     pos_y         vel_x         vel_y  ship_lander_angle  \\\n",
       "223515  0.000106  0.003625  4.711860e-04 -1.291953e-03           0.000133   \n",
       "72164  -0.000756  0.000276  9.414841e-04 -1.775322e-04           0.000672   \n",
       "193363  0.000068  0.000221  3.357693e-04 -6.056298e-04           0.000475   \n",
       "10987  -0.000061  0.000293  1.294753e-04 -7.730860e-04           0.000614   \n",
       "183186  0.000110 -0.000003 -5.025982e-07 -4.515411e-10          -0.000005   \n",
       "\n",
       "        ship_lander_angular_vel  leg_1_ground_contact  leg_2_ground_contact  \n",
       "223515             1.382630e-04              0.000000              0.000000  \n",
       "72164              1.499266e-04              0.000000              0.000000  \n",
       "193363             2.541082e-05              0.000000              0.000000  \n",
       "10987             -1.498529e-04              0.000000              0.000000  \n",
       "183186             1.446544e-07              0.003922              0.003922  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_plus_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Buiding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=100, total=  11.9s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=100 ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=50, n_estimators=100, total=  11.7s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=100, total=  11.8s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=100, total=  12.0s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=100, total=  11.7s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=150, total=  18.0s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=150, total=  17.7s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=150, total=  18.5s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=150, total=  18.4s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=150, total=  18.4s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=200, total=  27.8s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=200, total=  24.5s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=200, total=  25.2s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=200, total=  24.4s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=200, total=  25.1s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=250, total=  30.3s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=250, total=  30.2s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=250, total=  30.2s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=250, total=  31.2s\n",
      "[CV] max_features=2, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=2, min_samples_split=50, n_estimators=250, total=  30.7s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=100, total=  11.5s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=100, total=  11.6s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=100, total=  12.1s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=100, total=  12.7s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=100, total=  12.4s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=150, total=  19.0s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=150, total=  19.0s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=150, total=  18.5s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=150, total=  18.7s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=150, total=  19.3s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=200, total=  25.0s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=200, total=  24.7s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=200, total=  24.6s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=200, total=  24.9s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=200, total=  24.7s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=250, total=  30.8s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=250, total=  31.1s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=250, total=  31.0s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=250, total=  31.9s\n",
      "[CV] max_features=2, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=100, n_estimators=250, total=  31.0s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=100, total=  12.3s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=100, total=  12.6s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=100, total=  11.9s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=100, total=  11.8s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=100, total=  12.4s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=150, total=  17.6s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=150, total=  16.6s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=150, total=  16.6s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=150, total=  17.0s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=150, total=  17.2s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=200, total=  23.7s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=200, total=  23.2s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=200, total=  22.8s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=200, total=  23.3s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=200, total=  24.1s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=250, total=  30.9s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=250, total=  30.3s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=250 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=150, n_estimators=250, total=  30.2s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=250, total=  30.0s\n",
      "[CV] max_features=2, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=150, n_estimators=250, total=  29.7s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=100, total=  21.5s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=100, total=  21.4s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=100, total=  21.3s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=100, total=  21.1s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=100, total=  21.2s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=150, total=  32.1s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=150, total=  34.3s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=150, total=  31.9s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=150, total=  33.0s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=150, total=  33.2s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=200, total=  40.4s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=200, total=  41.0s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=200, total=  48.0s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=200, total=  46.5s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=200, total=  46.6s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=250, total=  53.5s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=250, total=  54.0s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=250, total=  53.6s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=250, total=  53.4s\n",
      "[CV] max_features=4, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=4, min_samples_split=50, n_estimators=250, total=  54.7s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=100, total=  20.6s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=100, total=  20.7s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=100, total=  20.5s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=100, total=  19.6s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=100, total=  19.4s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=150, total=  27.9s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=150, total=  27.6s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=150, total=  27.5s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=150, total=  27.2s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=150, total=  28.8s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=200, total=  37.3s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=200, total=  36.8s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=200, total=  37.0s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=200, total=  36.9s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=200, total=  36.9s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=250, total=  45.5s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=250, total=  45.3s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=250, total=  45.8s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=250, total=  45.5s\n",
      "[CV] max_features=4, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=100, n_estimators=250, total=  45.4s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=100, total=  17.6s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=100, total=  17.5s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=100, total=  17.6s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=100, total=  17.5s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=100, total=  17.3s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=150, total=  26.3s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=150, total=  26.3s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=150, total=  26.1s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=150, total=  26.4s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=150, total=  26.1s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=200, total=  34.9s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=200, total=  34.7s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=200, total=  35.1s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=200 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=4, min_samples_split=150, n_estimators=200, total=  35.2s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=200, total=  35.1s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=250, total=  43.3s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=250, total=  43.6s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=250, total=  43.8s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=250, total=  43.9s\n",
      "[CV] max_features=4, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=150, n_estimators=250, total=  43.5s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=100, total=  26.6s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=100, total=  26.6s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=100, total=  26.7s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=100, total=  26.7s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=100, total=  26.6s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=150, total=  41.1s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=150, total=  40.7s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=150, total=  41.0s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=150, total=  40.8s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=150, total=  41.0s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=200, total=  54.4s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=200, total=  54.3s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=200, total=  55.0s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=200, total=  54.2s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=200, total=  54.4s\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=6, min_samples_split=50, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=100, total=  25.7s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=100, total=  25.7s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=100, total=  25.9s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=100, total=  25.9s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=100, total=  25.6s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=150, total=  38.5s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=150, total=  38.4s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=150, total=  39.0s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=150, total=  38.7s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=150, total=  38.6s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=200, total=  51.4s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=200, total=  51.6s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=200, total=  51.4s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=200, total=  51.5s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=200, total=  51.3s\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=100, n_estimators=250, total= 1.1min\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=100, total=  24.5s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=100, total=  24.6s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=100, total=  24.8s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=100, total=  24.6s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=100, total=  24.8s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=150, total=  37.2s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=150, total=  37.2s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=150, total=  37.3s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=150, total=  37.4s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=6, min_samples_split=150, n_estimators=150, total=  37.3s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=200, total=  49.1s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=200, total=  49.6s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=200, total=  49.4s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=200, total=  49.6s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=200, total=  49.3s\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=250, total= 1.0min\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=250, total= 1.0min\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=250, total= 1.0min\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=250, total= 1.0min\n",
      "[CV] max_features=6, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=150, n_estimators=250, total= 1.0min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=100, total=  34.9s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=100, total=  35.3s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=100, total=  35.1s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=100, total=  34.9s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=100 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=100, total=  35.1s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=150, total=  52.3s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=150, total=  52.5s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=150, total=  52.7s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=150, total=  52.7s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=150 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=150, total=  52.9s\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=200, total= 1.2min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=200, total= 1.2min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=200, total= 1.2min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=200, total= 1.2min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=200 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=200, total= 1.2min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=250, total= 1.5min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=250, total= 1.5min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=250, total= 1.5min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=250, total= 1.5min\n",
      "[CV] max_features=8, min_samples_split=50, n_estimators=250 ..........\n",
      "[CV]  max_features=8, min_samples_split=50, n_estimators=250, total= 1.5min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=100, total=  33.2s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=100, total=  33.1s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=100, total=  33.2s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=100, total=  33.1s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=100, total=  33.1s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=150, total=  49.5s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=150, total=  49.7s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=150, total=  49.8s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=150, total=  49.5s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=150, total=  49.6s\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=250, total= 1.4min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=250, total= 1.4min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=250, total= 1.4min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=250, total= 1.4min\n",
      "[CV] max_features=8, min_samples_split=100, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=100, n_estimators=250, total= 1.4min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=100, total=  31.8s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=100, total=  31.8s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=100, total=  31.8s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=100, total=  31.9s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=100, total=  32.1s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=150, n_estimators=150, total=  47.5s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=150, total=  47.6s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=150, total=  48.2s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=150, total=  47.5s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=150, total=  47.8s\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=200, total= 1.1min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=250, total= 1.3min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=250, total= 1.3min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=250, total= 1.3min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=250, total= 1.3min\n",
      "[CV] max_features=8, min_samples_split=150, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=150, n_estimators=250, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 165.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [100, 150, 200, 250], 'max_features': [2, 4, 6, 8], 'min_samples_split': [50, 100, 150]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 300, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': list(range(50,200,50)) }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the tet data\n",
    "y_pred = my_tuned_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991968616640602"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['player_state.pkl']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(my_tuned_model, 'player_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('player_state.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  16.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   2.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   4.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  14.5s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   3.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  22.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  22.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  27.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  32.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  25.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  33.3s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  33.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  45.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  43.0s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  39.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  19.8s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  17.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  21.5s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  19.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  18.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  57.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  47.4s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  44.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  45.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  57.7s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total= 1.6min\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  39.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  49.5s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  39.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  37.5s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total= 4.2min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total= 4.2min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total= 3.6min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total= 3.3min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total= 3.7min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  49.0s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=38.7min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=30.3min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=25.7min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=37.8min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=18.3min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=15.6min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=12.5min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total= 7.0min\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total= 1.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total= 5.3min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total= 5.1min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total= 5.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total= 5.3min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total= 5.3min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=22.5min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=49.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=27.8min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=30.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total= 4.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=13.9min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=12.0min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=11.5min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total= 8.2min\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total= 5.8min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total= 1.3min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total= 2.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total= 2.9min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total= 2.7min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total= 2.4min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total= 2.5min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total= 2.1min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total= 1.6min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total= 2.6min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total= 2.2min\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total= 2.2min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total= 3.9min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total= 3.5min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total= 3.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total= 2.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total= 3.0min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total= 2.1min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total= 2.3min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total= 1.7min\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  28.2s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 502.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'hidden_layer_sizes': [400, (400, 200), (400, 200, 100)], 'alpha': [0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid1 = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model1 = GridSearchCV(neural_network.MLPClassifier(), param_grid1, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model1.fit(X_train_plus_valid, y_train_plus_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the tet data\n",
    "y_pred1 = my_tuned_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print performance details\n",
    "accuracy1 = metrics.accuracy_score(y_test, y_pred1) # , normalize=True, sample_weight=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984546876242478"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.6s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   0.6s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.5s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.4s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.5s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.9s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.9s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.9s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.8s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.9s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   1.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   1.0s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   1.0s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.8s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   1.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   1.2s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   1.3s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   1.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   1.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   1.3s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   1.3s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   1.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   1.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   1.3s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   1.3s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   1.4s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   1.4s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   1.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   1.4s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   1.4s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   1.4s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   1.4s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   1.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   1.4s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   1.6s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   1.6s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   1.4s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   1.3s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   1.4s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   1.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   1.8s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   1.6s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   1.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   1.7s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   1.9s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   1.9s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   1.9s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   1.6s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_neighbors': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid2 = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model2 = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid2, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model2.fit(X_train_plus_valid, y_train_plus_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the tet data\n",
    "y_pred2 = my_tuned_model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print performance details\n",
    "accuracy2 = metrics.accuracy_score(y_test, y_pred2) # , normalize=True, sample_weight=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356614626129828"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 32162\n",
      "Processed 1000 of 32162\n",
      "Processed 2000 of 32162\n",
      "Processed 3000 of 32162\n",
      "Processed 4000 of 32162\n",
      "Processed 5000 of 32162\n",
      "Processed 6000 of 32162\n",
      "Processed 7000 of 32162\n",
      "Processed 8000 of 32162\n",
      "Processed 9000 of 32162\n",
      "Processed 10000 of 32162\n",
      "Processed 11000 of 32162\n",
      "Processed 12000 of 32162\n",
      "Processed 13000 of 32162\n",
      "Processed 14000 of 32162\n",
      "Processed 15000 of 32162\n",
      "Processed 16000 of 32162\n",
      "Processed 17000 of 32162\n",
      "Processed 18000 of 32162\n",
      "Processed 19000 of 32162\n",
      "Processed 20000 of 32162\n",
      "Processed 21000 of 32162\n",
      "Processed 22000 of 32162\n",
      "Processed 23000 of 32162\n",
      "Processed 24000 of 32162\n",
      "Processed 25000 of 32162\n",
      "Processed 26000 of 32162\n",
      "Processed 27000 of 32162\n",
      "Processed 28000 of 32162\n",
      "Processed 29000 of 32162\n",
      "Processed 30000 of 32162\n",
      "Processed 31000 of 32162\n",
      "Processed 32000 of 32162\n",
      "Train shape: (32162, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set up some parmaeters for data loading\n",
    "TRAIN_DIR = './data/'\n",
    "sample_rate = 0.5\n",
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 1\n",
    "\n",
    "# generate filenames from the data folder and do sampling\n",
    "image_filenames = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if not i.startswith('.')] # use this for full dataset\n",
    "image_filenames = random.sample(image_filenames, int(len(image_filenames)*sample_rate))\n",
    "\n",
    "# Create a data array for image data\n",
    "count = len(image_filenames)\n",
    "data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.float)\n",
    "\n",
    "# Iterate throuigh the filenames and for each one load the image, resize and normalise\n",
    "for i, image_file in enumerate(image_filenames):\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)        \n",
    "    data[i] = image\n",
    "    data[i] = data[i]/255\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n",
    "\n",
    "print(\"Train shape: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the lables from the last characters in the filename\n",
    "labels = []\n",
    "for i in image_filenames:\n",
    "    l = i[-6:-5]\n",
    "    labels.append(int(l))\n",
    "        \n",
    "# Count the number of clases\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "# convert to binary encoded labels\n",
    "labels_wide = keras.utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(data, labels, random_state=0, test_size = 0.2, train_size = 0.8)\n",
    "train_labels_wide = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels_wide = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the random under-sampling (balance the traning dataset)\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "train_rus, train_labels_rus, idx_resampled = rus.fit_sample(train.reshape(len(train), ROWS*COLS*CHANNELS), train_labels)\n",
    "train_rus, train_labels_rus = shuffle(train_rus, train_labels_rus)\n",
    "train_rus = train_rus.reshape(len(train_rus), CHANNELS,ROWS, COLS)\n",
    "train_labels_rus_wide = keras.utils.to_categorical(train_labels_rus, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model - 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 32, 32)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1572992   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,587,700\n",
      "Trainable params: 1,587,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8289 samples, validate on 2763 samples\n",
      "Epoch 1/30\n",
      "8289/8289 [==============================] - 100s 12ms/step - loss: 1.2737 - acc: 0.3826 - val_loss: 1.1226 - val_acc: 0.4730\n",
      "Epoch 2/30\n",
      "8289/8289 [==============================] - 99s 12ms/step - loss: 1.0940 - acc: 0.4843 - val_loss: 1.0372 - val_acc: 0.5074\n",
      "Epoch 3/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 1.0332 - acc: 0.5204 - val_loss: 0.9938 - val_acc: 0.5349\n",
      "Epoch 4/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 0.9990 - acc: 0.5246 - val_loss: 0.9794 - val_acc: 0.5349\n",
      "Epoch 5/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 0.9705 - acc: 0.5412 - val_loss: 0.9725 - val_acc: 0.5360\n",
      "Epoch 6/30\n",
      "8289/8289 [==============================] - 115s 14ms/step - loss: 0.9526 - acc: 0.5530 - val_loss: 0.9594 - val_acc: 0.5519\n",
      "Epoch 7/30\n",
      "8289/8289 [==============================] - 112s 14ms/step - loss: 0.9283 - acc: 0.5685 - val_loss: 0.9507 - val_acc: 0.5476\n",
      "Epoch 8/30\n",
      "8289/8289 [==============================] - 103s 12ms/step - loss: 0.9098 - acc: 0.5757 - val_loss: 0.9413 - val_acc: 0.5509\n",
      "Epoch 9/30\n",
      "8289/8289 [==============================] - 104s 12ms/step - loss: 0.8805 - acc: 0.5898 - val_loss: 0.9364 - val_acc: 0.5559\n",
      "Epoch 10/30\n",
      "8289/8289 [==============================] - 100s 12ms/step - loss: 0.8621 - acc: 0.5957 - val_loss: 0.9365 - val_acc: 0.5682\n",
      "Epoch 11/30\n",
      "8289/8289 [==============================] - 97s 12ms/step - loss: 0.8331 - acc: 0.6221 - val_loss: 0.9203 - val_acc: 0.5689\n",
      "Epoch 12/30\n",
      "8289/8289 [==============================] - 99s 12ms/step - loss: 0.8125 - acc: 0.6195 - val_loss: 0.9257 - val_acc: 0.5784\n",
      "Epoch 13/30\n",
      "8289/8289 [==============================] - 100s 12ms/step - loss: 0.7916 - acc: 0.6301 - val_loss: 0.9068 - val_acc: 0.5813\n",
      "Epoch 14/30\n",
      "8289/8289 [==============================] - 99s 12ms/step - loss: 0.7566 - acc: 0.6594 - val_loss: 0.9091 - val_acc: 0.5820\n",
      "Epoch 15/30\n",
      "8289/8289 [==============================] - 100s 12ms/step - loss: 0.7455 - acc: 0.6659 - val_loss: 0.9168 - val_acc: 0.5889\n",
      "Epoch 16/30\n",
      "8289/8289 [==============================] - 109s 13ms/step - loss: 0.7164 - acc: 0.6729 - val_loss: 0.9026 - val_acc: 0.5928\n",
      "Epoch 17/30\n",
      "8289/8289 [==============================] - 107s 13ms/step - loss: 0.6902 - acc: 0.6893 - val_loss: 0.8992 - val_acc: 0.5943\n",
      "Epoch 18/30\n",
      "8289/8289 [==============================] - 105s 13ms/step - loss: 0.6650 - acc: 0.6991 - val_loss: 0.9228 - val_acc: 0.5889\n",
      "Epoch 19/30\n",
      "8289/8289 [==============================] - 105s 13ms/step - loss: 0.6530 - acc: 0.7043 - val_loss: 0.9467 - val_acc: 0.5870\n",
      "Epoch 20/30\n",
      "8289/8289 [==============================] - 99s 12ms/step - loss: 0.6349 - acc: 0.7149 - val_loss: 0.9268 - val_acc: 0.5965\n",
      "Epoch 21/30\n",
      "8289/8289 [==============================] - 100s 12ms/step - loss: 0.6035 - acc: 0.7288 - val_loss: 0.9548 - val_acc: 0.5979\n",
      "Epoch 22/30\n",
      "8289/8289 [==============================] - 112s 14ms/step - loss: 0.5887 - acc: 0.7403 - val_loss: 0.9714 - val_acc: 0.5914\n",
      "Epoch 23/30\n",
      "8289/8289 [==============================] - 101s 12ms/step - loss: 0.5685 - acc: 0.7502 - val_loss: 0.9624 - val_acc: 0.5954\n",
      "Epoch 24/30\n",
      "8289/8289 [==============================] - 102s 12ms/step - loss: 0.5496 - acc: 0.7584 - val_loss: 0.9821 - val_acc: 0.6048\n",
      "Epoch 25/30\n",
      "8289/8289 [==============================] - 99s 12ms/step - loss: 0.5316 - acc: 0.7641 - val_loss: 0.9939 - val_acc: 0.5983\n",
      "Epoch 26/30\n",
      "8289/8289 [==============================] - 97s 12ms/step - loss: 0.5167 - acc: 0.7748 - val_loss: 1.0206 - val_acc: 0.6033\n",
      "Epoch 27/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 0.4972 - acc: 0.7796 - val_loss: 1.0534 - val_acc: 0.5965\n",
      "Epoch 28/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 0.4876 - acc: 0.7867 - val_loss: 1.0657 - val_acc: 0.6055\n",
      "Epoch 29/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 0.4789 - acc: 0.7909 - val_loss: 1.0847 - val_acc: 0.5943\n",
      "Epoch 30/30\n",
      "8289/8289 [==============================] - 98s 12ms/step - loss: 0.4588 - acc: 0.7995 - val_loss: 1.0772 - val_acc: 0.6055\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "history = model1.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt4+qKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123a929b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Test Data ********\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.47      0.48      2416\n",
      "          1       0.52      0.73      0.61       674\n",
      "          2       0.53      0.43      0.48      2654\n",
      "          3       0.48      0.72      0.57       689\n",
      "\n",
      "avg / total       0.51      0.51      0.50      6433\n",
      "\n",
      "Confusion Matrix\n",
      "[[1137  190  831  258]\n",
      " [  91  492   84    7]\n",
      " [ 987  252 1143  272]\n",
      " [  95   12   88  494]]\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred1 = model1.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred1))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred1))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076946992072128\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(test_labels, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model - 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 32, 32)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 16, 16)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 566,836\n",
      "Trainable params: 566,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8289 samples, validate on 2763 samples\n",
      "Epoch 1/30\n",
      "8289/8289 [==============================] - 112s 14ms/step - loss: 1.2593 - acc: 0.3840 - val_loss: 1.1258 - val_acc: 0.4767\n",
      "Epoch 2/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 1.1046 - acc: 0.4770 - val_loss: 1.0532 - val_acc: 0.4962\n",
      "Epoch 3/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 1.0577 - acc: 0.5034 - val_loss: 1.0234 - val_acc: 0.5089\n",
      "Epoch 4/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 1.0295 - acc: 0.5171 - val_loss: 1.0031 - val_acc: 0.5208\n",
      "Epoch 5/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 1.0007 - acc: 0.5294 - val_loss: 0.9935 - val_acc: 0.5168\n",
      "Epoch 6/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 0.9874 - acc: 0.5354 - val_loss: 0.9739 - val_acc: 0.5335\n",
      "Epoch 7/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.9549 - acc: 0.5437 - val_loss: 0.9565 - val_acc: 0.5414\n",
      "Epoch 8/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.9324 - acc: 0.5605 - val_loss: 0.9427 - val_acc: 0.5519\n",
      "Epoch 9/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.8921 - acc: 0.5769 - val_loss: 0.9174 - val_acc: 0.5581\n",
      "Epoch 10/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.8673 - acc: 0.5905 - val_loss: 0.8933 - val_acc: 0.5693\n",
      "Epoch 11/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.8385 - acc: 0.6109 - val_loss: 0.8999 - val_acc: 0.5780\n",
      "Epoch 12/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 0.8116 - acc: 0.6197 - val_loss: 0.8824 - val_acc: 0.5813\n",
      "Epoch 13/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 0.7844 - acc: 0.6273 - val_loss: 0.8852 - val_acc: 0.5928\n",
      "Epoch 14/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.7595 - acc: 0.6422 - val_loss: 0.8673 - val_acc: 0.5946\n",
      "Epoch 15/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.7462 - acc: 0.6524 - val_loss: 0.8534 - val_acc: 0.6069\n",
      "Epoch 16/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.7221 - acc: 0.6617 - val_loss: 0.8898 - val_acc: 0.5845\n",
      "Epoch 17/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.7030 - acc: 0.6703 - val_loss: 0.8478 - val_acc: 0.6033\n",
      "Epoch 18/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.6795 - acc: 0.6787 - val_loss: 0.8585 - val_acc: 0.6127\n",
      "Epoch 19/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.6574 - acc: 0.6986 - val_loss: 0.8459 - val_acc: 0.6127\n",
      "Epoch 20/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.6461 - acc: 0.7020 - val_loss: 0.8821 - val_acc: 0.6026\n",
      "Epoch 21/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.6318 - acc: 0.7148 - val_loss: 0.8679 - val_acc: 0.6062\n",
      "Epoch 22/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.5982 - acc: 0.7235 - val_loss: 0.8906 - val_acc: 0.6037\n",
      "Epoch 23/30\n",
      "8289/8289 [==============================] - 110s 13ms/step - loss: 0.5894 - acc: 0.7353 - val_loss: 0.8711 - val_acc: 0.6269\n",
      "Epoch 24/30\n",
      "8289/8289 [==============================] - 111s 13ms/step - loss: 0.5628 - acc: 0.7445 - val_loss: 0.8850 - val_acc: 0.6178\n",
      "Epoch 25/30\n",
      "8289/8289 [==============================] - 112s 14ms/step - loss: 0.5484 - acc: 0.7521 - val_loss: 0.9290 - val_acc: 0.6200\n",
      "Epoch 26/30\n",
      "8289/8289 [==============================] - 113s 14ms/step - loss: 0.5277 - acc: 0.7575 - val_loss: 0.9154 - val_acc: 0.6182\n",
      "Epoch 27/30\n",
      "8289/8289 [==============================] - 113s 14ms/step - loss: 0.5131 - acc: 0.7757 - val_loss: 0.9518 - val_acc: 0.6232\n",
      "Epoch 28/30\n",
      "8289/8289 [==============================] - 113s 14ms/step - loss: 0.5004 - acc: 0.7786 - val_loss: 0.9215 - val_acc: 0.6214\n",
      "Epoch 29/30\n",
      "8289/8289 [==============================] - 113s 14ms/step - loss: 0.4713 - acc: 0.7879 - val_loss: 1.0134 - val_acc: 0.6160\n",
      "Epoch 30/30\n",
      "8289/8289 [==============================] - 113s 14ms/step - loss: 0.4651 - acc: 0.7942 - val_loss: 0.9860 - val_acc: 0.6254\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "history = model2.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFbCAYAAAD80gauAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTIqLxFRESCzP8DHPrVRYxp0N8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1254d7ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Test Data ********\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.50      0.52      2416\n",
      "          1       0.39      0.83      0.53       674\n",
      "          2       0.66      0.38      0.49      2654\n",
      "          3       0.43      0.78      0.56       689\n",
      "\n",
      "avg / total       0.56      0.51      0.51      6433\n",
      "\n",
      "Confusion Matrix\n",
      "[[1198  440  439  339]\n",
      " [  75  557   35    7]\n",
      " [ 869  414 1019  352]\n",
      " [  89   23   40  537]]\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred2 = model2.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred2))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred2))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514689880304679\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(test_labels, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model - 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 32, 32)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 48, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 16, 16)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 80, 8, 8)          46160     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 80, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 252,548\n",
      "Trainable params: 252,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8289 samples, validate on 2763 samples\n",
      "Epoch 1/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.2948 - acc: 0.3501 - val_loss: 1.1590 - val_acc: 0.4263\n",
      "Epoch 2/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.1241 - acc: 0.4645 - val_loss: 1.0697 - val_acc: 0.4955\n",
      "Epoch 3/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 1.0584 - acc: 0.4973 - val_loss: 1.0227 - val_acc: 0.5031\n",
      "Epoch 4/30\n",
      "8289/8289 [==============================] - 123s 15ms/step - loss: 1.0266 - acc: 0.5121 - val_loss: 1.0124 - val_acc: 0.5118\n",
      "Epoch 5/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.0142 - acc: 0.5186 - val_loss: 1.0019 - val_acc: 0.5027\n",
      "Epoch 6/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.9853 - acc: 0.5236 - val_loss: 0.9782 - val_acc: 0.5150\n",
      "Epoch 7/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.9525 - acc: 0.5458 - val_loss: 0.9334 - val_acc: 0.5574\n",
      "Epoch 8/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.9119 - acc: 0.5537 - val_loss: 0.9154 - val_acc: 0.5559\n",
      "Epoch 9/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.8813 - acc: 0.5743 - val_loss: 0.8872 - val_acc: 0.5689\n",
      "Epoch 10/30\n",
      "8289/8289 [==============================] - 115s 14ms/step - loss: 0.8400 - acc: 0.5921 - val_loss: 0.9036 - val_acc: 0.5784\n",
      "Epoch 11/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.8106 - acc: 0.5996 - val_loss: 0.8470 - val_acc: 0.5849\n",
      "Epoch 12/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.7873 - acc: 0.6138 - val_loss: 0.8434 - val_acc: 0.5943\n",
      "Epoch 13/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.7655 - acc: 0.6246 - val_loss: 0.8584 - val_acc: 0.6019\n",
      "Epoch 14/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.7516 - acc: 0.6281 - val_loss: 0.8361 - val_acc: 0.6012\n",
      "Epoch 15/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.7369 - acc: 0.6389 - val_loss: 0.8113 - val_acc: 0.5997\n",
      "Epoch 16/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.7086 - acc: 0.6517 - val_loss: 0.8320 - val_acc: 0.6120\n",
      "Epoch 17/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6898 - acc: 0.6651 - val_loss: 0.8222 - val_acc: 0.6160\n",
      "Epoch 18/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6800 - acc: 0.6644 - val_loss: 0.8441 - val_acc: 0.6124\n",
      "Epoch 19/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6632 - acc: 0.6799 - val_loss: 0.8453 - val_acc: 0.6069\n",
      "Epoch 20/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6400 - acc: 0.6936 - val_loss: 0.8331 - val_acc: 0.6149\n",
      "Epoch 21/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6240 - acc: 0.6933 - val_loss: 0.8467 - val_acc: 0.6211\n",
      "Epoch 22/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6120 - acc: 0.7076 - val_loss: 0.8617 - val_acc: 0.6142\n",
      "Epoch 23/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.6009 - acc: 0.7115 - val_loss: 0.8537 - val_acc: 0.6174\n",
      "Epoch 24/30\n",
      "8289/8289 [==============================] - 115s 14ms/step - loss: 0.5702 - acc: 0.7345 - val_loss: 0.8996 - val_acc: 0.6167\n",
      "Epoch 25/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.5396 - acc: 0.7473 - val_loss: 0.9382 - val_acc: 0.6062\n",
      "Epoch 26/30\n",
      "8289/8289 [==============================] - 114s 14ms/step - loss: 0.5299 - acc: 0.7522 - val_loss: 0.9577 - val_acc: 0.6098\n",
      "Epoch 27/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.5144 - acc: 0.7605 - val_loss: 0.9885 - val_acc: 0.6109\n",
      "Epoch 28/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.5013 - acc: 0.7710 - val_loss: 0.9667 - val_acc: 0.6120\n",
      "Epoch 29/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.4733 - acc: 0.7854 - val_loss: 0.9471 - val_acc: 0.6142\n",
      "Epoch 30/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.4631 - acc: 0.7912 - val_loss: 1.0231 - val_acc: 0.6069\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "history = model3.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8271b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Test Data ********\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.48      0.49      2416\n",
      "          1       0.54      0.77      0.63       674\n",
      "          2       0.56      0.48      0.52      2654\n",
      "          3       0.57      0.72      0.64       689\n",
      "\n",
      "avg / total       0.54      0.54      0.53      6433\n",
      "\n",
      "Confusion Matrix\n",
      "[[1167  217  851  181]\n",
      " [  88  516   59   11]\n",
      " [ 983  216 1268  187]\n",
      " [ 113   10   69  497]]\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred3 = model3.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred3))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred3))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5359863205347427\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(test_labels, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model - 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 48, 32, 32)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 48, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 16, 16)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 80, 8, 8)          46160     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 80, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 96, 4, 4)          69216     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 96, 2, 2)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 207,076\n",
      "Trainable params: 207,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(96, (3, 3), padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "\n",
    "model4.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8289 samples, validate on 2763 samples\n",
      "Epoch 1/30\n",
      "8289/8289 [==============================] - 118s 14ms/step - loss: 1.2996 - acc: 0.3418 - val_loss: 1.1581 - val_acc: 0.4307\n",
      "Epoch 2/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.1205 - acc: 0.4654 - val_loss: 1.0657 - val_acc: 0.4897\n",
      "Epoch 3/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.0611 - acc: 0.4972 - val_loss: 1.0242 - val_acc: 0.5049\n",
      "Epoch 4/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.0240 - acc: 0.5153 - val_loss: 1.0066 - val_acc: 0.5208\n",
      "Epoch 5/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 1.0037 - acc: 0.5213 - val_loss: 0.9861 - val_acc: 0.5212\n",
      "Epoch 6/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.9805 - acc: 0.5328 - val_loss: 0.9665 - val_acc: 0.5378\n",
      "Epoch 7/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.9430 - acc: 0.5460 - val_loss: 0.9554 - val_acc: 0.5487\n",
      "Epoch 8/30\n",
      "8289/8289 [==============================] - 118s 14ms/step - loss: 0.8990 - acc: 0.5662 - val_loss: 0.8955 - val_acc: 0.5776\n",
      "Epoch 9/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.8544 - acc: 0.5843 - val_loss: 0.9030 - val_acc: 0.5744\n",
      "Epoch 10/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.8214 - acc: 0.6008 - val_loss: 0.8755 - val_acc: 0.5780\n",
      "Epoch 11/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.7913 - acc: 0.6060 - val_loss: 0.8421 - val_acc: 0.5849\n",
      "Epoch 12/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.7658 - acc: 0.6168 - val_loss: 0.8556 - val_acc: 0.5878\n",
      "Epoch 13/30\n",
      "8289/8289 [==============================] - 120s 15ms/step - loss: 0.7448 - acc: 0.6305 - val_loss: 0.8588 - val_acc: 0.5943\n",
      "Epoch 14/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.7304 - acc: 0.6399 - val_loss: 0.8494 - val_acc: 0.5972\n",
      "Epoch 15/30\n",
      "8289/8289 [==============================] - 122s 15ms/step - loss: 0.7231 - acc: 0.6439 - val_loss: 0.8144 - val_acc: 0.6088\n",
      "Epoch 16/30\n",
      "8289/8289 [==============================] - 125s 15ms/step - loss: 0.6940 - acc: 0.6510 - val_loss: 0.8156 - val_acc: 0.6008\n",
      "Epoch 17/30\n",
      "8289/8289 [==============================] - 124s 15ms/step - loss: 0.6609 - acc: 0.6739 - val_loss: 0.8727 - val_acc: 0.6091\n",
      "Epoch 18/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.6526 - acc: 0.6798 - val_loss: 0.8553 - val_acc: 0.6113\n",
      "Epoch 19/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.6401 - acc: 0.6863 - val_loss: 0.8724 - val_acc: 0.6048\n",
      "Epoch 20/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.6249 - acc: 0.6926 - val_loss: 0.8455 - val_acc: 0.6156\n",
      "Epoch 21/30\n",
      "8289/8289 [==============================] - 118s 14ms/step - loss: 0.5968 - acc: 0.7065 - val_loss: 0.9143 - val_acc: 0.6145\n",
      "Epoch 22/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.5733 - acc: 0.7263 - val_loss: 0.9721 - val_acc: 0.6124\n",
      "Epoch 23/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.5621 - acc: 0.7277 - val_loss: 0.8958 - val_acc: 0.6225\n",
      "Epoch 24/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.5376 - acc: 0.7429 - val_loss: 0.9877 - val_acc: 0.6131\n",
      "Epoch 25/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.5145 - acc: 0.7580 - val_loss: 0.9415 - val_acc: 0.6077\n",
      "Epoch 26/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.4888 - acc: 0.7714 - val_loss: 0.9868 - val_acc: 0.6214\n",
      "Epoch 27/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.4665 - acc: 0.7822 - val_loss: 1.0766 - val_acc: 0.6077\n",
      "Epoch 28/30\n",
      "8289/8289 [==============================] - 118s 14ms/step - loss: 0.4559 - acc: 0.7931 - val_loss: 1.0666 - val_acc: 0.6127\n",
      "Epoch 29/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.4360 - acc: 0.8009 - val_loss: 1.0950 - val_acc: 0.6149\n",
      "Epoch 30/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.3953 - acc: 0.8201 - val_loss: 1.0895 - val_acc: 0.6102\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "history = model4.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt4iIiJ9ReYuIiPgZlbeIiIif+X9pque98P1+hAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8d3ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Test Data ********\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.54      0.52      2416\n",
      "          1       0.49      0.77      0.60       674\n",
      "          2       0.61      0.38      0.47      2654\n",
      "          3       0.49      0.76      0.59       689\n",
      "\n",
      "avg / total       0.54      0.52      0.52      6433\n",
      "\n",
      "Confusion Matrix\n",
      "[[1315  273  561  267]\n",
      " [ 104  518   46    6]\n",
      " [1112  249 1020  273]\n",
      " [ 124    9   34  522]]\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred4 = model4.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred4))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred4))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5246385823099643\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(test_labels, pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model - 6 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 48, 32, 32)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 48, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 16, 16)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 80, 8, 8)          46160     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 80, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 96, 4, 4)          69216     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 96, 2, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 108, 2, 2)         93420     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 108, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 108)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               13952     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 265,168\n",
      "Trainable params: 265,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3), padding='same', input_shape=(CHANNELS, ROWS, COLS), activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Conv2D(96, (3, 3), padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Conv2D(108, (3, 3), padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "\n",
    "model5.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy', optimizer=adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11052"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8289 samples, validate on 2763 samples\n",
      "Epoch 1/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 1.3202 - acc: 0.3300 - val_loss: 1.1589 - val_acc: 0.4390\n",
      "Epoch 2/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 1.1356 - acc: 0.4652 - val_loss: 1.0708 - val_acc: 0.4911\n",
      "Epoch 3/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 1.0540 - acc: 0.5052 - val_loss: 1.0164 - val_acc: 0.5045\n",
      "Epoch 4/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 1.0220 - acc: 0.5161 - val_loss: 1.0069 - val_acc: 0.5157\n",
      "Epoch 5/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.9975 - acc: 0.5244 - val_loss: 0.9748 - val_acc: 0.5237\n",
      "Epoch 6/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.9654 - acc: 0.5437 - val_loss: 0.9485 - val_acc: 0.5371\n",
      "Epoch 7/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.9227 - acc: 0.5530 - val_loss: 0.9238 - val_acc: 0.5519\n",
      "Epoch 8/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.8775 - acc: 0.5744 - val_loss: 0.9208 - val_acc: 0.5661\n",
      "Epoch 9/30\n",
      "8289/8289 [==============================] - 116s 14ms/step - loss: 0.8437 - acc: 0.5798 - val_loss: 0.8713 - val_acc: 0.5831\n",
      "Epoch 10/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.8031 - acc: 0.6000 - val_loss: 0.8738 - val_acc: 0.5816\n",
      "Epoch 11/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.7838 - acc: 0.5991 - val_loss: 0.8208 - val_acc: 0.5993\n",
      "Epoch 12/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.7421 - acc: 0.6221 - val_loss: 0.8258 - val_acc: 0.5889\n",
      "Epoch 13/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.7356 - acc: 0.6299 - val_loss: 0.8362 - val_acc: 0.5863\n",
      "Epoch 14/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.7036 - acc: 0.6436 - val_loss: 0.8335 - val_acc: 0.5867\n",
      "Epoch 15/30\n",
      "8289/8289 [==============================] - 117s 14ms/step - loss: 0.6895 - acc: 0.6529 - val_loss: 0.8296 - val_acc: 0.6095\n",
      "Epoch 16/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.6803 - acc: 0.6574 - val_loss: 0.8635 - val_acc: 0.5936\n",
      "Epoch 17/30\n",
      "8289/8289 [==============================] - 118s 14ms/step - loss: 0.6570 - acc: 0.6704 - val_loss: 0.8888 - val_acc: 0.5965\n",
      "Epoch 18/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.6371 - acc: 0.6837 - val_loss: 0.9029 - val_acc: 0.6102\n",
      "Epoch 19/30\n",
      "8289/8289 [==============================] - 122s 15ms/step - loss: 0.6110 - acc: 0.6956 - val_loss: 0.9079 - val_acc: 0.5932\n",
      "Epoch 20/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.5853 - acc: 0.7100 - val_loss: 0.9416 - val_acc: 0.6019\n",
      "Epoch 21/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.5762 - acc: 0.7185 - val_loss: 0.9306 - val_acc: 0.5983\n",
      "Epoch 22/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.5465 - acc: 0.7308 - val_loss: 0.9410 - val_acc: 0.6109\n",
      "Epoch 23/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.5302 - acc: 0.7495 - val_loss: 1.0235 - val_acc: 0.6051\n",
      "Epoch 24/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.5017 - acc: 0.7664 - val_loss: 1.0126 - val_acc: 0.6041\n",
      "Epoch 25/30\n",
      "8289/8289 [==============================] - 119s 14ms/step - loss: 0.4889 - acc: 0.7760 - val_loss: 1.1348 - val_acc: 0.5914\n",
      "Epoch 26/30\n",
      "8289/8289 [==============================] - 120s 14ms/step - loss: 0.4424 - acc: 0.7982 - val_loss: 1.1982 - val_acc: 0.6012\n",
      "Epoch 27/30\n",
      "8289/8289 [==============================] - 122s 15ms/step - loss: 0.4372 - acc: 0.7972 - val_loss: 1.1194 - val_acc: 0.5957\n",
      "Epoch 28/30\n",
      "8289/8289 [==============================] - 121s 15ms/step - loss: 0.4268 - acc: 0.8106 - val_loss: 1.1393 - val_acc: 0.6084\n",
      "Epoch 29/30\n",
      "8289/8289 [==============================] - 120s 15ms/step - loss: 0.3814 - acc: 0.8309 - val_loss: 1.2312 - val_acc: 0.5957\n",
      "Epoch 30/30\n",
      "8289/8289 [==============================] - 122s 15ms/step - loss: 0.3655 - acc: 0.8383 - val_loss: 1.2893 - val_acc: 0.6015\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "history = model5.fit(train_rus, train_labels_rus_wide, batch_size=batch_size, epochs=epochs, validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRBCCCsjxVsIIYSwMv8P0GfbKplLZxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a95b5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Test Data ********\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.49      0.49      2416\n",
      "          1       0.43      0.77      0.55       674\n",
      "          2       0.59      0.37      0.45      2654\n",
      "          3       0.45      0.76      0.57       689\n",
      "\n",
      "avg / total       0.52      0.50      0.49      6433\n",
      "\n",
      "Confusion Matrix\n",
      "[[1191  329  580  316]\n",
      " [  94  516   58    6]\n",
      " [1037  326  977  314]\n",
      " [ 107   17   40  525]]\n"
     ]
    }
   ],
   "source": [
    "print(\"****** Test Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "pred5 = model5.predict_classes(test)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(test_labels, pred5))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(test_labels, pred5))\n",
    "#display(pd.crosstab(test_labels, list(pred), margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49883413648375563\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(test_labels, pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"player_images_2.mod\"\n",
    "model3.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "ENV_NAME = 'LunarLander-v2'\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                450       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                3825      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               7600      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 404       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 12,279\n",
      "Trainable params: 12,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(75))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=500000, window_length=1)\n",
    "policy = EpsGreedyQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy, enable_double_dqn=False)\n",
    "dqn.compile(Adam(lr=0.002, decay=2.25e-05), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejoonsung/anaconda/lib/python3.6/site-packages/rl/memory.py:29: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    71/100000: episode: 1, duration: 1.289s, episode steps: 71, steps per second: 55, episode reward: -159.436, mean reward: -2.246 [-100.000, 13.179], mean action: 1.493 [0.000, 3.000], mean observation: 0.007 [-1.497, 5.697], loss: 2.913820, mean_absolute_error: 2.114091, mean_q: -0.438274\n",
      "   168/100000: episode: 2, duration: 0.332s, episode steps: 97, steps per second: 293, episode reward: -369.158, mean reward: -3.806 [-100.000, 2.444], mean action: 2.031 [0.000, 3.000], mean observation: 0.244 [-1.755, 2.615], loss: 28.878475, mean_absolute_error: 3.345076, mean_q: -1.194434\n",
      "   461/100000: episode: 3, duration: 1.119s, episode steps: 293, steps per second: 262, episode reward: -329.103, mean reward: -1.123 [-100.000, 45.166], mean action: 1.614 [0.000, 3.000], mean observation: 0.014 [-1.153, 2.335], loss: 26.448143, mean_absolute_error: 5.743047, mean_q: -3.752707\n",
      "   595/100000: episode: 4, duration: 0.462s, episode steps: 134, steps per second: 290, episode reward: -456.621, mean reward: -3.408 [-100.000, 84.338], mean action: 1.313 [0.000, 3.000], mean observation: 0.176 [-1.523, 3.834], loss: 16.429419, mean_absolute_error: 7.354524, mean_q: -4.636876\n",
      "   664/100000: episode: 5, duration: 0.234s, episode steps: 69, steps per second: 294, episode reward: -200.353, mean reward: -2.904 [-100.000, 6.457], mean action: 0.333 [0.000, 3.000], mean observation: -0.150 [-4.229, 1.000], loss: 19.616833, mean_absolute_error: 9.877035, mean_q: -6.943088\n",
      "  1169/100000: episode: 6, duration: 2.010s, episode steps: 505, steps per second: 251, episode reward: -268.420, mean reward: -0.532 [-100.000, 21.515], mean action: 1.883 [0.000, 3.000], mean observation: 0.005 [-1.097, 1.727], loss: 12.866938, mean_absolute_error: 9.871364, mean_q: -6.965560\n",
      "  1343/100000: episode: 7, duration: 0.668s, episode steps: 174, steps per second: 260, episode reward: -192.332, mean reward: -1.105 [-100.000, 19.243], mean action: 1.994 [0.000, 3.000], mean observation: 0.023 [-1.161, 2.312], loss: 7.162632, mean_absolute_error: 10.450699, mean_q: -6.179631\n",
      "  2343/100000: episode: 8, duration: 4.519s, episode steps: 1000, steps per second: 221, episode reward: -191.243, mean reward: -0.191 [-4.691, 4.368], mean action: 1.944 [0.000, 3.000], mean observation: 0.178 [-0.336, 1.072], loss: 9.257378, mean_absolute_error: 12.413497, mean_q: -6.141102\n",
      "  3343/100000: episode: 9, duration: 4.124s, episode steps: 1000, steps per second: 242, episode reward: -127.413, mean reward: -0.127 [-4.784, 3.410], mean action: 1.841 [0.000, 3.000], mean observation: 0.182 [-0.286, 1.040], loss: 7.073332, mean_absolute_error: 12.707726, mean_q: -4.384903\n",
      "  3553/100000: episode: 10, duration: 0.796s, episode steps: 210, steps per second: 264, episode reward: -138.905, mean reward: -0.661 [-100.000, 2.808], mean action: 1.943 [0.000, 3.000], mean observation: 0.240 [-0.375, 1.002], loss: 6.303771, mean_absolute_error: 12.034600, mean_q: -2.891106\n",
      "  4373/100000: episode: 11, duration: 3.371s, episode steps: 820, steps per second: 243, episode reward: -287.484, mean reward: -0.351 [-100.000, 3.747], mean action: 1.771 [0.000, 3.000], mean observation: 0.180 [-0.385, 1.003], loss: 3.365906, mean_absolute_error: 11.456333, mean_q: -1.819708\n",
      "  4760/100000: episode: 12, duration: 1.534s, episode steps: 387, steps per second: 252, episode reward: -257.674, mean reward: -0.666 [-100.000, 2.824], mean action: 1.654 [0.000, 3.000], mean observation: 0.074 [-0.439, 1.000], loss: 5.734747, mean_absolute_error: 11.879107, mean_q: -1.585413\n",
      "  4926/100000: episode: 13, duration: 0.581s, episode steps: 166, steps per second: 286, episode reward: -205.910, mean reward: -1.240 [-100.000, 8.736], mean action: 1.892 [0.000, 3.000], mean observation: 0.140 [-2.848, 1.002], loss: 5.001964, mean_absolute_error: 11.355001, mean_q: -0.005968\n",
      "  5337/100000: episode: 14, duration: 1.563s, episode steps: 411, steps per second: 263, episode reward: -164.210, mean reward: -0.400 [-100.000, 4.737], mean action: 1.820 [0.000, 3.000], mean observation: 0.015 [-3.074, 1.000], loss: 6.180479, mean_absolute_error: 12.267172, mean_q: 1.311230\n",
      "  6337/100000: episode: 15, duration: 4.510s, episode steps: 1000, steps per second: 222, episode reward: -179.207, mean reward: -0.179 [-4.757, 3.205], mean action: 1.406 [0.000, 3.000], mean observation: 0.132 [-0.593, 1.033], loss: 3.877571, mean_absolute_error: 12.427764, mean_q: 2.775629\n",
      "  6539/100000: episode: 16, duration: 0.720s, episode steps: 202, steps per second: 280, episode reward: -256.695, mean reward: -1.271 [-100.000, 2.965], mean action: 1.579 [0.000, 3.000], mean observation: -0.024 [-1.108, 0.976], loss: 2.449044, mean_absolute_error: 12.571565, mean_q: 3.402935\n",
      "  7102/100000: episode: 17, duration: 2.449s, episode steps: 563, steps per second: 230, episode reward: -191.749, mean reward: -0.341 [-100.000, 21.776], mean action: 1.540 [0.000, 3.000], mean observation: 0.043 [-1.201, 1.889], loss: 2.921851, mean_absolute_error: 12.907813, mean_q: 4.866331\n",
      "  7533/100000: episode: 18, duration: 1.741s, episode steps: 431, steps per second: 248, episode reward: -280.243, mean reward: -0.650 [-100.000, 52.645], mean action: 1.705 [0.000, 3.000], mean observation: -0.007 [-2.069, 1.186], loss: 4.212525, mean_absolute_error: 14.046055, mean_q: 6.912603\n",
      "  7695/100000: episode: 19, duration: 0.588s, episode steps: 162, steps per second: 276, episode reward: -275.581, mean reward: -1.701 [-100.000, 99.643], mean action: 1.327 [0.000, 3.000], mean observation: 0.082 [-2.086, 1.078], loss: 7.524745, mean_absolute_error: 14.937430, mean_q: 9.118956\n",
      "  8007/100000: episode: 20, duration: 1.193s, episode steps: 312, steps per second: 262, episode reward: -314.058, mean reward: -1.007 [-100.000, 22.539], mean action: 1.609 [0.000, 3.000], mean observation: -0.039 [-4.003, 1.246], loss: 6.353675, mean_absolute_error: 14.983885, mean_q: 8.123390\n",
      "  9007/100000: episode: 21, duration: 5.379s, episode steps: 1000, steps per second: 186, episode reward: -172.409, mean reward: -0.172 [-4.721, 4.211], mean action: 1.653 [0.000, 3.000], mean observation: 0.052 [-0.987, 1.009], loss: 6.640830, mean_absolute_error: 14.573695, mean_q: 8.964209\n",
      "  9905/100000: episode: 22, duration: 3.846s, episode steps: 898, steps per second: 233, episode reward: -223.812, mean reward: -0.249 [-100.000, 10.329], mean action: 1.667 [0.000, 3.000], mean observation: -0.015 [-0.927, 3.578], loss: 5.979225, mean_absolute_error: 15.583921, mean_q: 11.277981\n",
      " 10112/100000: episode: 23, duration: 0.754s, episode steps: 207, steps per second: 275, episode reward: -156.093, mean reward: -0.754 [-100.000, 2.557], mean action: 1.773 [0.000, 3.000], mean observation: 0.257 [-0.372, 1.103], loss: 2.958818, mean_absolute_error: 15.765131, mean_q: 12.728823\n",
      " 10218/100000: episode: 24, duration: 0.378s, episode steps: 106, steps per second: 280, episode reward: -171.354, mean reward: -1.617 [-100.000, 1.180], mean action: 1.679 [0.000, 3.000], mean observation: -0.080 [-1.137, 0.968], loss: 3.650489, mean_absolute_error: 16.395927, mean_q: 12.227655\n",
      " 11218/100000: episode: 25, duration: 4.200s, episode steps: 1000, steps per second: 238, episode reward: -144.195, mean reward: -0.144 [-5.282, 4.939], mean action: 1.718 [0.000, 3.000], mean observation: -0.019 [-0.830, 0.979], loss: 4.292060, mean_absolute_error: 16.637169, mean_q: 12.935524\n",
      " 11620/100000: episode: 26, duration: 1.485s, episode steps: 402, steps per second: 271, episode reward: -161.927, mean reward: -0.403 [-100.000, 5.475], mean action: 1.714 [0.000, 3.000], mean observation: -0.059 [-1.001, 0.968], loss: 4.257180, mean_absolute_error: 17.569857, mean_q: 14.238269\n",
      " 12435/100000: episode: 27, duration: 3.519s, episode steps: 815, steps per second: 232, episode reward: -454.849, mean reward: -0.558 [-100.000, 4.440], mean action: 1.685 [0.000, 3.000], mean observation: 0.038 [-0.811, 1.850], loss: 5.134373, mean_absolute_error: 17.394712, mean_q: 14.438104\n",
      " 12671/100000: episode: 28, duration: 0.952s, episode steps: 236, steps per second: 248, episode reward: -166.277, mean reward: -0.705 [-100.000, 3.644], mean action: 1.466 [0.000, 3.000], mean observation: -0.045 [-1.005, 0.924], loss: 8.245346, mean_absolute_error: 17.260702, mean_q: 14.224545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12860/100000: episode: 29, duration: 0.674s, episode steps: 189, steps per second: 280, episode reward: -158.725, mean reward: -0.840 [-100.000, 4.257], mean action: 1.481 [0.000, 3.000], mean observation: -0.066 [-1.001, 0.942], loss: 6.219909, mean_absolute_error: 17.440815, mean_q: 14.171348\n",
      " 13000/100000: episode: 30, duration: 0.491s, episode steps: 140, steps per second: 285, episode reward: -143.593, mean reward: -1.026 [-100.000, 17.340], mean action: 1.900 [0.000, 3.000], mean observation: 0.056 [-0.977, 2.956], loss: 5.849504, mean_absolute_error: 17.113703, mean_q: 15.039374\n",
      " 13426/100000: episode: 31, duration: 1.702s, episode steps: 426, steps per second: 250, episode reward: -209.221, mean reward: -0.491 [-100.000, 9.315], mean action: 1.765 [0.000, 3.000], mean observation: 0.074 [-0.677, 1.182], loss: 4.505347, mean_absolute_error: 17.080147, mean_q: 14.835071\n",
      " 14426/100000: episode: 32, duration: 4.688s, episode steps: 1000, steps per second: 213, episode reward: -109.504, mean reward: -0.110 [-4.063, 5.418], mean action: 1.615 [0.000, 3.000], mean observation: 0.024 [-0.738, 0.937], loss: 5.616982, mean_absolute_error: 17.765055, mean_q: 14.879861\n",
      " 14800/100000: episode: 33, duration: 1.510s, episode steps: 374, steps per second: 248, episode reward: -249.012, mean reward: -0.666 [-100.000, 5.647], mean action: 1.824 [0.000, 3.000], mean observation: -0.009 [-1.136, 0.927], loss: 6.142231, mean_absolute_error: 17.816326, mean_q: 14.954794\n",
      " 15429/100000: episode: 34, duration: 2.772s, episode steps: 629, steps per second: 227, episode reward: -277.572, mean reward: -0.441 [-100.000, 14.423], mean action: 1.711 [0.000, 3.000], mean observation: 0.089 [-0.822, 2.567], loss: 5.639331, mean_absolute_error: 17.978531, mean_q: 15.151318\n",
      " 15554/100000: episode: 35, duration: 0.454s, episode steps: 125, steps per second: 275, episode reward: -625.143, mean reward: -5.001 [-100.000, 1.364], mean action: 1.840 [0.000, 3.000], mean observation: 0.162 [-3.342, 1.580], loss: 3.455667, mean_absolute_error: 17.951551, mean_q: 14.110923\n",
      " 15952/100000: episode: 36, duration: 1.582s, episode steps: 398, steps per second: 252, episode reward: -216.682, mean reward: -0.544 [-100.000, 36.212], mean action: 1.822 [0.000, 3.000], mean observation: 0.084 [-2.269, 1.000], loss: 7.688658, mean_absolute_error: 18.679832, mean_q: 15.424104\n",
      " 16952/100000: episode: 37, duration: 5.253s, episode steps: 1000, steps per second: 190, episode reward: -171.514, mean reward: -0.172 [-5.365, 5.541], mean action: 1.721 [0.000, 3.000], mean observation: 0.131 [-0.553, 0.941], loss: 5.542582, mean_absolute_error: 18.689182, mean_q: 15.506250\n",
      " 17952/100000: episode: 38, duration: 5.653s, episode steps: 1000, steps per second: 177, episode reward: -96.449, mean reward: -0.096 [-4.850, 6.405], mean action: 1.654 [0.000, 3.000], mean observation: 0.075 [-0.626, 0.978], loss: 5.967768, mean_absolute_error: 19.846867, mean_q: 17.433954\n",
      " 18952/100000: episode: 39, duration: 5.372s, episode steps: 1000, steps per second: 186, episode reward: -122.607, mean reward: -0.123 [-5.089, 4.518], mean action: 1.609 [0.000, 3.000], mean observation: 0.048 [-0.620, 0.929], loss: 5.140137, mean_absolute_error: 21.229290, mean_q: 19.909000\n",
      " 19380/100000: episode: 40, duration: 1.861s, episode steps: 428, steps per second: 230, episode reward: -136.211, mean reward: -0.318 [-100.000, 7.865], mean action: 1.762 [0.000, 3.000], mean observation: 0.073 [-0.726, 1.000], loss: 5.686977, mean_absolute_error: 22.643198, mean_q: 21.563372\n",
      " 20380/100000: episode: 41, duration: 4.808s, episode steps: 1000, steps per second: 208, episode reward: -116.577, mean reward: -0.117 [-4.826, 5.300], mean action: 1.594 [0.000, 3.000], mean observation: 0.034 [-0.467, 0.932], loss: 5.715350, mean_absolute_error: 23.373543, mean_q: 22.810539\n",
      " 21380/100000: episode: 42, duration: 4.892s, episode steps: 1000, steps per second: 204, episode reward: -82.663, mean reward: -0.083 [-4.314, 4.027], mean action: 1.782 [0.000, 3.000], mean observation: 0.056 [-0.453, 0.927], loss: 5.258346, mean_absolute_error: 23.939800, mean_q: 24.087637\n",
      " 22380/100000: episode: 43, duration: 4.750s, episode steps: 1000, steps per second: 211, episode reward: -160.252, mean reward: -0.160 [-4.278, 4.094], mean action: 1.835 [0.000, 3.000], mean observation: 0.024 [-0.446, 0.939], loss: 5.551262, mean_absolute_error: 23.684584, mean_q: 24.740484\n",
      " 23380/100000: episode: 44, duration: 4.900s, episode steps: 1000, steps per second: 204, episode reward: -87.567, mean reward: -0.088 [-4.569, 5.268], mean action: 1.621 [0.000, 3.000], mean observation: 0.034 [-0.617, 0.988], loss: 3.476404, mean_absolute_error: 23.697399, mean_q: 25.334126\n",
      " 24380/100000: episode: 45, duration: 5.008s, episode steps: 1000, steps per second: 200, episode reward: -80.449, mean reward: -0.080 [-4.384, 5.427], mean action: 1.514 [0.000, 3.000], mean observation: 0.046 [-0.514, 1.023], loss: 4.222991, mean_absolute_error: 23.813904, mean_q: 26.066887\n",
      " 25380/100000: episode: 46, duration: 4.867s, episode steps: 1000, steps per second: 205, episode reward: -55.917, mean reward: -0.056 [-4.621, 4.207], mean action: 1.459 [0.000, 3.000], mean observation: 0.026 [-0.586, 0.998], loss: 4.536233, mean_absolute_error: 23.787416, mean_q: 26.477093\n",
      " 26380/100000: episode: 47, duration: 4.691s, episode steps: 1000, steps per second: 213, episode reward: -136.764, mean reward: -0.137 [-5.231, 4.735], mean action: 1.669 [0.000, 3.000], mean observation: 0.071 [-0.624, 1.020], loss: 4.549258, mean_absolute_error: 24.105095, mean_q: 27.339590\n",
      " 26746/100000: episode: 48, duration: 1.449s, episode steps: 366, steps per second: 253, episode reward: -290.706, mean reward: -0.794 [-100.000, 50.150], mean action: 1.555 [0.000, 3.000], mean observation: -0.053 [-1.873, 1.431], loss: 4.701232, mean_absolute_error: 24.777489, mean_q: 28.103842\n",
      " 27541/100000: episode: 49, duration: 3.908s, episode steps: 795, steps per second: 203, episode reward: -205.301, mean reward: -0.258 [-100.000, 9.767], mean action: 1.678 [0.000, 3.000], mean observation: 0.016 [-0.807, 1.238], loss: 4.418740, mean_absolute_error: 25.202858, mean_q: 28.885048\n",
      " 27737/100000: episode: 50, duration: 0.679s, episode steps: 196, steps per second: 289, episode reward: -34.666, mean reward: -0.177 [-100.000, 20.849], mean action: 1.531 [0.000, 3.000], mean observation: 0.075 [-0.751, 1.490], loss: 3.765135, mean_absolute_error: 25.315380, mean_q: 28.949055\n",
      " 27853/100000: episode: 51, duration: 0.411s, episode steps: 116, steps per second: 282, episode reward: -153.544, mean reward: -1.324 [-100.000, 2.733], mean action: 1.948 [0.000, 3.000], mean observation: 0.243 [-0.503, 1.004], loss: 2.146861, mean_absolute_error: 25.462627, mean_q: 29.167675\n",
      " 28447/100000: episode: 52, duration: 2.435s, episode steps: 594, steps per second: 244, episode reward: -124.557, mean reward: -0.210 [-100.000, 11.413], mean action: 1.544 [0.000, 3.000], mean observation: 0.013 [-0.718, 1.000], loss: 3.979742, mean_absolute_error: 25.982834, mean_q: 29.238667\n",
      " 28631/100000: episode: 53, duration: 0.645s, episode steps: 184, steps per second: 285, episode reward: -473.511, mean reward: -2.573 [-100.000, 3.701], mean action: 1.957 [0.000, 3.000], mean observation: 0.030 [-2.376, 1.811], loss: 4.598081, mean_absolute_error: 26.905586, mean_q: 30.105658\n",
      " 28798/100000: episode: 54, duration: 0.576s, episode steps: 167, steps per second: 290, episode reward: -312.066, mean reward: -1.869 [-100.000, 6.386], mean action: 1.784 [0.000, 3.000], mean observation: 0.056 [-1.705, 3.335], loss: 4.553044, mean_absolute_error: 26.494059, mean_q: 30.090912\n",
      " 29077/100000: episode: 55, duration: 1.096s, episode steps: 279, steps per second: 255, episode reward: -154.256, mean reward: -0.553 [-100.000, 9.384], mean action: 1.667 [0.000, 3.000], mean observation: 0.039 [-0.824, 2.599], loss: 5.960405, mean_absolute_error: 27.317162, mean_q: 30.489779\n",
      " 29925/100000: episode: 56, duration: 3.845s, episode steps: 848, steps per second: 221, episode reward: 114.981, mean reward: 0.136 [-20.640, 100.000], mean action: 1.741 [0.000, 3.000], mean observation: 0.113 [-0.867, 1.060], loss: 6.074378, mean_absolute_error: 28.091198, mean_q: 31.153154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30095/100000: episode: 57, duration: 0.565s, episode steps: 170, steps per second: 301, episode reward: -210.745, mean reward: -1.240 [-100.000, 9.301], mean action: 1.541 [0.000, 3.000], mean observation: -0.017 [-1.310, 1.243], loss: 6.687345, mean_absolute_error: 28.588858, mean_q: 31.100519\n",
      " 31095/100000: episode: 58, duration: 5.068s, episode steps: 1000, steps per second: 197, episode reward: -59.659, mean reward: -0.060 [-18.970, 20.372], mean action: 1.884 [0.000, 3.000], mean observation: 0.091 [-0.742, 1.000], loss: 7.401373, mean_absolute_error: 30.087063, mean_q: 33.383282\n",
      " 31214/100000: episode: 59, duration: 0.439s, episode steps: 119, steps per second: 271, episode reward: -127.023, mean reward: -1.067 [-100.000, 10.465], mean action: 1.605 [0.000, 3.000], mean observation: -0.014 [-0.942, 1.666], loss: 7.463102, mean_absolute_error: 30.992332, mean_q: 35.685619\n",
      " 31511/100000: episode: 60, duration: 1.090s, episode steps: 297, steps per second: 272, episode reward: -231.970, mean reward: -0.781 [-100.000, 13.957], mean action: 1.609 [0.000, 3.000], mean observation: -0.018 [-1.069, 1.000], loss: 9.768226, mean_absolute_error: 32.106094, mean_q: 35.694939\n",
      " 32511/100000: episode: 61, duration: 5.022s, episode steps: 1000, steps per second: 199, episode reward: -66.911, mean reward: -0.067 [-23.312, 24.192], mean action: 1.590 [0.000, 3.000], mean observation: 0.007 [-0.804, 1.203], loss: 8.267701, mean_absolute_error: 33.592422, mean_q: 39.084759\n",
      " 33511/100000: episode: 62, duration: 3.925s, episode steps: 1000, steps per second: 255, episode reward: -103.591, mean reward: -0.104 [-4.647, 4.031], mean action: 1.526 [0.000, 3.000], mean observation: -0.049 [-0.707, 0.967], loss: 6.238258, mean_absolute_error: 37.257851, mean_q: 45.119797\n",
      " 33637/100000: episode: 63, duration: 0.423s, episode steps: 126, steps per second: 298, episode reward: -242.852, mean reward: -1.927 [-100.000, 63.209], mean action: 1.905 [0.000, 3.000], mean observation: 0.025 [-1.134, 1.708], loss: 4.627470, mean_absolute_error: 39.000454, mean_q: 48.672836\n",
      " 33809/100000: episode: 64, duration: 0.572s, episode steps: 172, steps per second: 301, episode reward: -110.367, mean reward: -0.642 [-100.000, 13.150], mean action: 1.500 [0.000, 3.000], mean observation: 0.006 [-0.880, 1.003], loss: 7.793904, mean_absolute_error: 39.165745, mean_q: 48.370289\n",
      " 34809/100000: episode: 65, duration: 4.557s, episode steps: 1000, steps per second: 219, episode reward: -108.673, mean reward: -0.109 [-12.414, 17.922], mean action: 1.733 [0.000, 3.000], mean observation: -0.039 [-0.761, 1.000], loss: 7.118735, mean_absolute_error: 40.809891, mean_q: 50.866360\n",
      " 35039/100000: episode: 66, duration: 0.788s, episode steps: 230, steps per second: 292, episode reward: -81.605, mean reward: -0.355 [-100.000, 42.610], mean action: 1.665 [0.000, 3.000], mean observation: 0.019 [-1.391, 1.436], loss: 4.940965, mean_absolute_error: 41.929672, mean_q: 52.586269\n",
      " 35216/100000: episode: 67, duration: 0.599s, episode steps: 177, steps per second: 296, episode reward: -130.756, mean reward: -0.739 [-100.000, 9.803], mean action: 1.610 [0.000, 3.000], mean observation: 0.034 [-1.658, 1.000], loss: 11.073022, mean_absolute_error: 42.022179, mean_q: 51.976971\n",
      " 35366/100000: episode: 68, duration: 0.516s, episode steps: 150, steps per second: 290, episode reward: -137.963, mean reward: -0.920 [-100.000, 9.599], mean action: 1.447 [0.000, 3.000], mean observation: -0.023 [-1.553, 1.000], loss: 6.734097, mean_absolute_error: 42.040516, mean_q: 52.167976\n",
      " 35521/100000: episode: 69, duration: 0.551s, episode steps: 155, steps per second: 281, episode reward: -188.665, mean reward: -1.217 [-100.000, 9.845], mean action: 1.658 [0.000, 3.000], mean observation: 0.022 [-1.268, 2.392], loss: 11.027706, mean_absolute_error: 42.430077, mean_q: 53.044506\n",
      " 36521/100000: episode: 70, duration: 4.508s, episode steps: 1000, steps per second: 222, episode reward: -116.026, mean reward: -0.116 [-4.821, 7.741], mean action: 1.737 [0.000, 3.000], mean observation: -0.013 [-0.777, 0.934], loss: 6.104928, mean_absolute_error: 42.506081, mean_q: 53.602398\n",
      " 36650/100000: episode: 71, duration: 0.449s, episode steps: 129, steps per second: 287, episode reward: -125.734, mean reward: -0.975 [-100.000, 15.474], mean action: 1.457 [0.000, 3.000], mean observation: -0.042 [-1.248, 1.000], loss: 6.539025, mean_absolute_error: 42.560417, mean_q: 53.967659\n",
      " 37650/100000: episode: 72, duration: 5.403s, episode steps: 1000, steps per second: 185, episode reward: -58.086, mean reward: -0.058 [-14.935, 22.614], mean action: 1.656 [0.000, 3.000], mean observation: 0.014 [-0.665, 1.000], loss: 7.677893, mean_absolute_error: 42.551250, mean_q: 53.775452\n",
      " 38594/100000: episode: 73, duration: 3.912s, episode steps: 944, steps per second: 241, episode reward: -369.342, mean reward: -0.391 [-100.000, 17.253], mean action: 1.862 [0.000, 3.000], mean observation: 0.023 [-0.837, 1.273], loss: 6.031103, mean_absolute_error: 42.535080, mean_q: 54.132656\n",
      " 38814/100000: episode: 74, duration: 0.765s, episode steps: 220, steps per second: 288, episode reward: -117.707, mean reward: -0.535 [-100.000, 18.179], mean action: 1.691 [0.000, 3.000], mean observation: 0.011 [-2.018, 1.000], loss: 8.875830, mean_absolute_error: 42.484749, mean_q: 54.012657\n",
      " 39311/100000: episode: 75, duration: 2.063s, episode steps: 497, steps per second: 241, episode reward: -437.632, mean reward: -0.881 [-100.000, 6.925], mean action: 1.759 [0.000, 3.000], mean observation: -0.003 [-3.859, 1.931], loss: 7.784240, mean_absolute_error: 41.996792, mean_q: 53.618694\n",
      " 40307/100000: episode: 76, duration: 4.473s, episode steps: 996, steps per second: 223, episode reward: 55.311, mean reward: 0.056 [-13.959, 100.000], mean action: 1.635 [0.000, 3.000], mean observation: 0.037 [-1.308, 1.000], loss: 7.154364, mean_absolute_error: 42.180378, mean_q: 53.600395\n",
      " 40733/100000: episode: 77, duration: 1.678s, episode steps: 426, steps per second: 254, episode reward: 202.886, mean reward: 0.476 [-13.741, 100.000], mean action: 2.195 [0.000, 3.000], mean observation: 0.039 [-0.861, 1.000], loss: 8.022147, mean_absolute_error: 41.810188, mean_q: 53.128338\n",
      " 41269/100000: episode: 78, duration: 2.018s, episode steps: 536, steps per second: 266, episode reward: -282.807, mean reward: -0.528 [-100.000, 9.270], mean action: 1.662 [0.000, 3.000], mean observation: 0.053 [-0.621, 1.001], loss: 6.191148, mean_absolute_error: 41.702736, mean_q: 53.086643\n",
      " 42269/100000: episode: 79, duration: 4.570s, episode steps: 1000, steps per second: 219, episode reward: -91.659, mean reward: -0.092 [-6.872, 6.137], mean action: 1.671 [0.000, 3.000], mean observation: 0.035 [-0.525, 0.925], loss: 8.523740, mean_absolute_error: 41.503124, mean_q: 52.316704\n",
      " 43269/100000: episode: 80, duration: 5.285s, episode steps: 1000, steps per second: 189, episode reward: -99.448, mean reward: -0.099 [-5.291, 6.417], mean action: 1.683 [0.000, 3.000], mean observation: 0.018 [-0.667, 0.931], loss: 7.771361, mean_absolute_error: 40.849407, mean_q: 51.541946\n",
      " 44269/100000: episode: 81, duration: 4.769s, episode steps: 1000, steps per second: 210, episode reward: -120.683, mean reward: -0.121 [-3.322, 5.067], mean action: 1.734 [0.000, 3.000], mean observation: 0.016 [-0.394, 0.938], loss: 7.951737, mean_absolute_error: 40.709133, mean_q: 51.417965\n",
      " 45269/100000: episode: 82, duration: 4.487s, episode steps: 1000, steps per second: 223, episode reward: -67.350, mean reward: -0.067 [-4.809, 5.709], mean action: 1.691 [0.000, 3.000], mean observation: 0.018 [-0.437, 0.996], loss: 7.628831, mean_absolute_error: 40.746487, mean_q: 51.372631\n",
      " 45764/100000: episode: 83, duration: 2.001s, episode steps: 495, steps per second: 247, episode reward: 119.090, mean reward: 0.241 [-21.649, 100.000], mean action: 1.612 [0.000, 3.000], mean observation: 0.047 [-0.603, 1.000], loss: 7.051583, mean_absolute_error: 40.731682, mean_q: 51.379807\n",
      " 46268/100000: episode: 84, duration: 1.952s, episode steps: 504, steps per second: 258, episode reward: -105.191, mean reward: -0.209 [-100.000, 9.886], mean action: 1.802 [0.000, 3.000], mean observation: -0.036 [-0.717, 1.000], loss: 10.557729, mean_absolute_error: 41.358067, mean_q: 52.088818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46931/100000: episode: 85, duration: 2.669s, episode steps: 663, steps per second: 248, episode reward: -186.693, mean reward: -0.282 [-100.000, 14.827], mean action: 1.567 [0.000, 3.000], mean observation: -0.013 [-0.950, 1.000], loss: 8.901178, mean_absolute_error: 41.742264, mean_q: 52.442272\n",
      " 47931/100000: episode: 86, duration: 4.411s, episode steps: 1000, steps per second: 227, episode reward: -91.041, mean reward: -0.091 [-23.994, 14.085], mean action: 1.723 [0.000, 3.000], mean observation: -0.013 [-0.733, 1.047], loss: 7.268562, mean_absolute_error: 42.707458, mean_q: 53.732731\n",
      " 48931/100000: episode: 87, duration: 4.869s, episode steps: 1000, steps per second: 205, episode reward: -339.468, mean reward: -0.339 [-12.818, 23.687], mean action: 1.802 [0.000, 3.000], mean observation: -0.004 [-0.863, 1.329], loss: 9.650045, mean_absolute_error: 43.472580, mean_q: 55.074574\n",
      " 49931/100000: episode: 88, duration: 4.202s, episode steps: 1000, steps per second: 238, episode reward: -110.717, mean reward: -0.111 [-24.325, 13.810], mean action: 1.829 [0.000, 3.000], mean observation: -0.022 [-0.587, 1.000], loss: 8.811601, mean_absolute_error: 43.894264, mean_q: 55.822884\n",
      " 50931/100000: episode: 89, duration: 4.579s, episode steps: 1000, steps per second: 218, episode reward: -75.934, mean reward: -0.076 [-4.491, 4.530], mean action: 1.492 [0.000, 3.000], mean observation: -0.007 [-0.773, 1.177], loss: 7.088871, mean_absolute_error: 44.038265, mean_q: 55.920139\n",
      " 51931/100000: episode: 90, duration: 5.112s, episode steps: 1000, steps per second: 196, episode reward: -82.568, mean reward: -0.083 [-4.320, 4.954], mean action: 1.710 [0.000, 3.000], mean observation: -0.037 [-0.617, 0.987], loss: 8.869570, mean_absolute_error: 44.458691, mean_q: 56.783360\n",
      " 52699/100000: episode: 91, duration: 3.204s, episode steps: 768, steps per second: 240, episode reward: 158.324, mean reward: 0.206 [-13.536, 100.000], mean action: 1.117 [0.000, 3.000], mean observation: 0.050 [-0.772, 1.000], loss: 8.418671, mean_absolute_error: 44.019032, mean_q: 56.509521\n",
      " 52913/100000: episode: 92, duration: 0.764s, episode steps: 214, steps per second: 280, episode reward: -182.398, mean reward: -0.852 [-100.000, 2.815], mean action: 1.710 [0.000, 3.000], mean observation: -0.017 [-1.007, 1.048], loss: 6.173038, mean_absolute_error: 44.203472, mean_q: 57.283836\n",
      " 53661/100000: episode: 93, duration: 3.005s, episode steps: 748, steps per second: 249, episode reward: 195.480, mean reward: 0.261 [-18.689, 100.000], mean action: 1.578 [0.000, 3.000], mean observation: 0.161 [-0.618, 1.118], loss: 7.603540, mean_absolute_error: 44.395241, mean_q: 57.051491\n",
      " 54661/100000: episode: 94, duration: 4.228s, episode steps: 1000, steps per second: 237, episode reward: -116.186, mean reward: -0.116 [-4.207, 6.355], mean action: 1.634 [0.000, 3.000], mean observation: -0.056 [-0.889, 0.938], loss: 5.832006, mean_absolute_error: 44.278324, mean_q: 56.882717\n",
      " 55661/100000: episode: 95, duration: 4.696s, episode steps: 1000, steps per second: 213, episode reward: -134.771, mean reward: -0.135 [-6.388, 6.446], mean action: 1.847 [0.000, 3.000], mean observation: -0.042 [-0.969, 0.925], loss: 7.985006, mean_absolute_error: 44.897568, mean_q: 57.718529\n",
      " 56661/100000: episode: 96, duration: 4.413s, episode steps: 1000, steps per second: 227, episode reward: -228.812, mean reward: -0.229 [-4.737, 5.438], mean action: 1.792 [0.000, 3.000], mean observation: -0.012 [-0.852, 0.973], loss: 7.079536, mean_absolute_error: 44.861561, mean_q: 57.892235\n",
      " 57661/100000: episode: 97, duration: 4.529s, episode steps: 1000, steps per second: 221, episode reward: -119.144, mean reward: -0.119 [-12.125, 13.231], mean action: 1.709 [0.000, 3.000], mean observation: -0.053 [-0.897, 1.000], loss: 6.951335, mean_absolute_error: 44.580784, mean_q: 57.591671\n",
      " 58117/100000: episode: 98, duration: 1.985s, episode steps: 456, steps per second: 230, episode reward: 109.119, mean reward: 0.239 [-12.617, 100.000], mean action: 1.476 [0.000, 3.000], mean observation: 0.009 [-0.555, 1.000], loss: 6.967068, mean_absolute_error: 44.378571, mean_q: 57.254429\n",
      " 59117/100000: episode: 99, duration: 4.453s, episode steps: 1000, steps per second: 225, episode reward: -116.100, mean reward: -0.116 [-6.577, 5.249], mean action: 1.739 [0.000, 3.000], mean observation: -0.043 [-0.818, 0.938], loss: 5.932833, mean_absolute_error: 44.544811, mean_q: 57.547680\n",
      " 60117/100000: episode: 100, duration: 5.009s, episode steps: 1000, steps per second: 200, episode reward: -91.165, mean reward: -0.091 [-6.191, 5.544], mean action: 1.677 [0.000, 3.000], mean observation: -0.039 [-0.826, 1.011], loss: 5.636583, mean_absolute_error: 44.064259, mean_q: 57.067211\n",
      " 61117/100000: episode: 101, duration: 4.926s, episode steps: 1000, steps per second: 203, episode reward: -84.820, mean reward: -0.085 [-12.095, 16.200], mean action: 1.678 [0.000, 3.000], mean observation: -0.005 [-0.552, 1.142], loss: 6.961140, mean_absolute_error: 43.539162, mean_q: 56.339508\n",
      " 62117/100000: episode: 102, duration: 4.664s, episode steps: 1000, steps per second: 214, episode reward: -18.280, mean reward: -0.018 [-19.386, 19.530], mean action: 1.615 [0.000, 3.000], mean observation: 0.058 [-0.556, 1.000], loss: 5.787303, mean_absolute_error: 43.507683, mean_q: 56.192841\n",
      " 62322/100000: episode: 103, duration: 0.742s, episode steps: 205, steps per second: 276, episode reward: -267.907, mean reward: -1.307 [-100.000, 22.444], mean action: 2.161 [0.000, 3.000], mean observation: -0.009 [-0.658, 1.655], loss: 9.551622, mean_absolute_error: 43.662613, mean_q: 56.531689\n",
      " 62942/100000: episode: 104, duration: 2.747s, episode steps: 620, steps per second: 226, episode reward: -239.355, mean reward: -0.386 [-100.000, 40.628], mean action: 1.734 [0.000, 3.000], mean observation: 0.007 [-1.749, 1.252], loss: 4.713546, mean_absolute_error: 43.730209, mean_q: 56.388798\n",
      " 63133/100000: episode: 105, duration: 0.689s, episode steps: 191, steps per second: 277, episode reward: -84.049, mean reward: -0.440 [-100.000, 13.263], mean action: 1.634 [0.000, 3.000], mean observation: 0.008 [-1.223, 1.000], loss: 4.918898, mean_absolute_error: 43.365746, mean_q: 56.099056\n",
      " 63693/100000: episode: 106, duration: 2.633s, episode steps: 560, steps per second: 213, episode reward: 138.181, mean reward: 0.247 [-18.858, 100.000], mean action: 1.221 [0.000, 3.000], mean observation: 0.064 [-1.071, 1.000], loss: 8.997440, mean_absolute_error: 43.252728, mean_q: 55.539047\n",
      " 64693/100000: episode: 107, duration: 5.663s, episode steps: 1000, steps per second: 177, episode reward: -92.010, mean reward: -0.092 [-5.465, 5.491], mean action: 1.797 [0.000, 3.000], mean observation: -0.031 [-0.610, 1.004], loss: 5.686323, mean_absolute_error: 42.673187, mean_q: 54.595547\n",
      " 65123/100000: episode: 108, duration: 1.797s, episode steps: 430, steps per second: 239, episode reward: 171.514, mean reward: 0.399 [-20.037, 100.000], mean action: 1.228 [0.000, 3.000], mean observation: 0.090 [-1.175, 1.000], loss: 4.477831, mean_absolute_error: 42.175110, mean_q: 53.902000\n",
      " 65899/100000: episode: 109, duration: 3.362s, episode steps: 776, steps per second: 231, episode reward: 210.287, mean reward: 0.271 [-21.887, 100.000], mean action: 1.317 [0.000, 3.000], mean observation: 0.122 [-0.947, 1.482], loss: 8.500028, mean_absolute_error: 41.834263, mean_q: 53.068790\n",
      " 66318/100000: episode: 110, duration: 1.625s, episode steps: 419, steps per second: 258, episode reward: 165.196, mean reward: 0.394 [-18.725, 100.000], mean action: 1.284 [0.000, 3.000], mean observation: 0.080 [-0.684, 1.000], loss: 8.100353, mean_absolute_error: 41.444901, mean_q: 52.782345\n",
      " 66457/100000: episode: 111, duration: 0.468s, episode steps: 139, steps per second: 297, episode reward: -108.194, mean reward: -0.778 [-100.000, 14.694], mean action: 1.727 [0.000, 3.000], mean observation: -0.069 [-1.147, 1.000], loss: 6.937970, mean_absolute_error: 41.002838, mean_q: 52.686111\n",
      " 66640/100000: episode: 112, duration: 0.627s, episode steps: 183, steps per second: 292, episode reward: -108.716, mean reward: -0.594 [-100.000, 10.533], mean action: 1.678 [0.000, 3.000], mean observation: -0.084 [-1.561, 1.000], loss: 5.717927, mean_absolute_error: 41.096638, mean_q: 51.817608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67121/100000: episode: 113, duration: 1.815s, episode steps: 481, steps per second: 265, episode reward: 104.548, mean reward: 0.217 [-10.836, 100.000], mean action: 1.630 [0.000, 3.000], mean observation: 0.009 [-0.766, 1.000], loss: 7.074313, mean_absolute_error: 40.847324, mean_q: 52.365242\n",
      " 67221/100000: episode: 114, duration: 0.375s, episode steps: 100, steps per second: 266, episode reward: -50.587, mean reward: -0.506 [-100.000, 15.386], mean action: 1.700 [0.000, 3.000], mean observation: -0.116 [-0.923, 1.000], loss: 6.216272, mean_absolute_error: 40.760307, mean_q: 52.165874\n",
      " 67370/100000: episode: 115, duration: 0.541s, episode steps: 149, steps per second: 276, episode reward: -137.502, mean reward: -0.923 [-100.000, 11.496], mean action: 1.826 [0.000, 3.000], mean observation: -0.022 [-1.209, 1.000], loss: 3.885887, mean_absolute_error: 40.966251, mean_q: 53.235687\n",
      " 67721/100000: episode: 116, duration: 1.358s, episode steps: 351, steps per second: 258, episode reward: 153.216, mean reward: 0.437 [-11.611, 100.000], mean action: 1.085 [0.000, 3.000], mean observation: 0.024 [-1.212, 1.000], loss: 6.370631, mean_absolute_error: 40.944134, mean_q: 52.551399\n",
      " 68062/100000: episode: 117, duration: 1.329s, episode steps: 341, steps per second: 257, episode reward: -190.280, mean reward: -0.558 [-100.000, 17.851], mean action: 2.103 [0.000, 3.000], mean observation: 0.018 [-0.978, 1.000], loss: 8.892206, mean_absolute_error: 40.656219, mean_q: 52.321281\n",
      " 68395/100000: episode: 118, duration: 1.289s, episode steps: 333, steps per second: 258, episode reward: 84.858, mean reward: 0.255 [-14.073, 100.000], mean action: 1.763 [0.000, 3.000], mean observation: 0.004 [-0.726, 1.000], loss: 7.046099, mean_absolute_error: 40.453716, mean_q: 52.137417\n",
      " 69395/100000: episode: 119, duration: 4.552s, episode steps: 1000, steps per second: 220, episode reward: -40.150, mean reward: -0.040 [-19.832, 22.133], mean action: 1.529 [0.000, 3.000], mean observation: 0.048 [-0.855, 1.000], loss: 6.579983, mean_absolute_error: 40.404259, mean_q: 51.991306\n",
      " 70395/100000: episode: 120, duration: 4.809s, episode steps: 1000, steps per second: 208, episode reward: -100.870, mean reward: -0.101 [-6.087, 4.827], mean action: 1.594 [0.000, 3.000], mean observation: 0.030 [-0.503, 0.954], loss: 8.202541, mean_absolute_error: 39.937366, mean_q: 51.691833\n",
      " 71060/100000: episode: 121, duration: 3.032s, episode steps: 665, steps per second: 219, episode reward: 147.529, mean reward: 0.222 [-6.614, 100.000], mean action: 1.594 [0.000, 3.000], mean observation: 0.068 [-0.532, 1.000], loss: 7.181895, mean_absolute_error: 39.829758, mean_q: 51.245995\n",
      " 71709/100000: episode: 122, duration: 3.114s, episode steps: 649, steps per second: 208, episode reward: 122.920, mean reward: 0.189 [-18.515, 100.000], mean action: 1.499 [0.000, 3.000], mean observation: 0.050 [-0.503, 1.000], loss: 7.084940, mean_absolute_error: 39.675362, mean_q: 51.432949\n",
      " 71958/100000: episode: 123, duration: 0.915s, episode steps: 249, steps per second: 272, episode reward: -91.369, mean reward: -0.367 [-100.000, 7.080], mean action: 1.743 [0.000, 3.000], mean observation: -0.059 [-1.050, 1.000], loss: 4.483274, mean_absolute_error: 39.034985, mean_q: 50.446915\n",
      " 72958/100000: episode: 124, duration: 5.186s, episode steps: 1000, steps per second: 193, episode reward: 17.804, mean reward: 0.018 [-17.859, 20.666], mean action: 1.886 [0.000, 3.000], mean observation: 0.133 [-0.538, 1.000], loss: 5.344292, mean_absolute_error: 39.229710, mean_q: 50.588436\n",
      " 73958/100000: episode: 125, duration: 4.629s, episode steps: 1000, steps per second: 216, episode reward: -40.422, mean reward: -0.040 [-19.532, 13.876], mean action: 1.626 [0.000, 3.000], mean observation: 0.040 [-1.095, 1.108], loss: 8.352998, mean_absolute_error: 39.098274, mean_q: 50.036228\n",
      " 74888/100000: episode: 126, duration: 4.281s, episode steps: 930, steps per second: 217, episode reward: 102.521, mean reward: 0.110 [-18.969, 100.000], mean action: 1.472 [0.000, 3.000], mean observation: 0.052 [-1.152, 1.000], loss: 6.752605, mean_absolute_error: 38.953053, mean_q: 50.205738\n",
      " 75757/100000: episode: 127, duration: 4.168s, episode steps: 869, steps per second: 209, episode reward: 80.950, mean reward: 0.093 [-9.014, 100.000], mean action: 1.494 [0.000, 3.000], mean observation: 0.047 [-0.416, 1.000], loss: 5.481102, mean_absolute_error: 38.471466, mean_q: 49.662434\n",
      " 76742/100000: episode: 128, duration: 4.670s, episode steps: 985, steps per second: 211, episode reward: 124.042, mean reward: 0.126 [-19.814, 100.000], mean action: 1.329 [0.000, 3.000], mean observation: 0.107 [-0.797, 1.000], loss: 6.057560, mean_absolute_error: 38.632675, mean_q: 49.902714\n",
      " 77621/100000: episode: 129, duration: 3.684s, episode steps: 879, steps per second: 239, episode reward: 157.930, mean reward: 0.180 [-21.054, 100.000], mean action: 2.000 [0.000, 3.000], mean observation: 0.154 [-0.722, 1.000], loss: 5.849334, mean_absolute_error: 38.807167, mean_q: 49.973663\n",
      " 78077/100000: episode: 130, duration: 1.791s, episode steps: 456, steps per second: 255, episode reward: -227.318, mean reward: -0.499 [-100.000, 3.211], mean action: 1.550 [0.000, 3.000], mean observation: -0.009 [-1.001, 1.109], loss: 6.449456, mean_absolute_error: 38.361900, mean_q: 49.824638\n",
      " 79023/100000: episode: 131, duration: 4.175s, episode steps: 946, steps per second: 227, episode reward: 146.482, mean reward: 0.155 [-19.930, 100.000], mean action: 1.549 [0.000, 3.000], mean observation: 0.108 [-0.914, 1.000], loss: 5.723627, mean_absolute_error: 38.376171, mean_q: 50.038239\n",
      " 79831/100000: episode: 132, duration: 3.592s, episode steps: 808, steps per second: 225, episode reward: 159.011, mean reward: 0.197 [-10.987, 100.000], mean action: 1.485 [0.000, 3.000], mean observation: 0.107 [-1.113, 1.018], loss: 5.966568, mean_absolute_error: 38.475094, mean_q: 49.898777\n",
      " 80236/100000: episode: 133, duration: 1.505s, episode steps: 405, steps per second: 269, episode reward: 222.638, mean reward: 0.550 [-8.853, 100.000], mean action: 1.220 [0.000, 3.000], mean observation: 0.118 [-0.588, 1.000], loss: 4.996732, mean_absolute_error: 38.689613, mean_q: 50.347462\n",
      " 80854/100000: episode: 134, duration: 2.533s, episode steps: 618, steps per second: 244, episode reward: 171.326, mean reward: 0.277 [-8.251, 100.000], mean action: 1.615 [0.000, 3.000], mean observation: 0.052 [-0.535, 1.000], loss: 7.373523, mean_absolute_error: 38.757179, mean_q: 50.579967\n",
      " 81719/100000: episode: 135, duration: 3.689s, episode steps: 865, steps per second: 234, episode reward: -282.305, mean reward: -0.326 [-100.000, 21.454], mean action: 1.194 [0.000, 3.000], mean observation: 0.162 [-0.739, 1.047], loss: 5.961592, mean_absolute_error: 39.261040, mean_q: 51.290668\n",
      " 82719/100000: episode: 136, duration: 4.819s, episode steps: 1000, steps per second: 208, episode reward: 89.361, mean reward: 0.089 [-19.442, 24.474], mean action: 1.060 [0.000, 3.000], mean observation: 0.172 [-0.865, 1.000], loss: 5.314068, mean_absolute_error: 39.127750, mean_q: 50.737648\n",
      " 83413/100000: episode: 137, duration: 3.101s, episode steps: 694, steps per second: 224, episode reward: 180.197, mean reward: 0.260 [-19.182, 100.000], mean action: 1.591 [0.000, 3.000], mean observation: 0.132 [-0.685, 1.000], loss: 5.591554, mean_absolute_error: 39.689396, mean_q: 51.444622\n",
      " 84126/100000: episode: 138, duration: 2.969s, episode steps: 713, steps per second: 240, episode reward: 122.855, mean reward: 0.172 [-20.798, 100.000], mean action: 1.926 [0.000, 3.000], mean observation: 0.062 [-0.659, 1.000], loss: 6.360074, mean_absolute_error: 39.767067, mean_q: 51.489063\n",
      " 84551/100000: episode: 139, duration: 1.587s, episode steps: 425, steps per second: 268, episode reward: 226.696, mean reward: 0.533 [-4.414, 100.000], mean action: 1.546 [0.000, 3.000], mean observation: 0.043 [-0.917, 1.231], loss: 5.617634, mean_absolute_error: 39.963364, mean_q: 51.594944\n",
      " 85000/100000: episode: 140, duration: 1.803s, episode steps: 449, steps per second: 249, episode reward: 229.437, mean reward: 0.511 [-11.087, 100.000], mean action: 1.325 [0.000, 3.000], mean observation: 0.124 [-0.739, 1.000], loss: 5.855774, mean_absolute_error: 39.957561, mean_q: 51.732819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85556/100000: episode: 141, duration: 2.124s, episode steps: 556, steps per second: 262, episode reward: 194.639, mean reward: 0.350 [-17.990, 100.000], mean action: 1.586 [0.000, 3.000], mean observation: 0.112 [-0.611, 1.024], loss: 6.560996, mean_absolute_error: 40.203770, mean_q: 52.181370\n",
      " 85938/100000: episode: 142, duration: 1.518s, episode steps: 382, steps per second: 252, episode reward: 183.969, mean reward: 0.482 [-17.988, 100.000], mean action: 1.702 [0.000, 3.000], mean observation: 0.035 [-0.542, 1.000], loss: 3.605568, mean_absolute_error: 39.854256, mean_q: 51.797897\n",
      " 86938/100000: episode: 143, duration: 4.312s, episode steps: 1000, steps per second: 232, episode reward: 68.356, mean reward: 0.068 [-20.402, 22.532], mean action: 1.650 [0.000, 3.000], mean observation: 0.101 [-0.828, 1.000], loss: 5.417536, mean_absolute_error: 39.814342, mean_q: 51.795753\n",
      " 87938/100000: episode: 144, duration: 4.465s, episode steps: 1000, steps per second: 224, episode reward: -43.042, mean reward: -0.043 [-10.408, 12.808], mean action: 1.825 [0.000, 3.000], mean observation: 0.009 [-0.924, 1.000], loss: 5.810810, mean_absolute_error: 40.103306, mean_q: 51.991306\n",
      " 88656/100000: episode: 145, duration: 3.058s, episode steps: 718, steps per second: 235, episode reward: 198.780, mean reward: 0.277 [-11.221, 100.000], mean action: 1.486 [0.000, 3.000], mean observation: 0.105 [-0.732, 1.000], loss: 5.851983, mean_absolute_error: 40.058693, mean_q: 51.954769\n",
      " 88939/100000: episode: 146, duration: 1.084s, episode steps: 283, steps per second: 261, episode reward: 224.842, mean reward: 0.794 [-6.965, 100.000], mean action: 1.509 [0.000, 3.000], mean observation: 0.043 [-0.628, 1.000], loss: 5.662218, mean_absolute_error: 39.839516, mean_q: 51.510029\n",
      " 89641/100000: episode: 147, duration: 3.003s, episode steps: 702, steps per second: 234, episode reward: 167.468, mean reward: 0.239 [-19.744, 100.000], mean action: 1.842 [0.000, 3.000], mean observation: 0.143 [-0.559, 1.223], loss: 6.966951, mean_absolute_error: 39.559040, mean_q: 51.476753\n",
      " 90345/100000: episode: 148, duration: 3.012s, episode steps: 704, steps per second: 234, episode reward: 126.545, mean reward: 0.180 [-20.227, 100.000], mean action: 1.727 [0.000, 3.000], mean observation: 0.093 [-0.767, 1.000], loss: 6.128984, mean_absolute_error: 39.396694, mean_q: 51.234447\n",
      " 90463/100000: episode: 149, duration: 0.393s, episode steps: 118, steps per second: 301, episode reward: -145.323, mean reward: -1.232 [-100.000, 2.852], mean action: 1.542 [0.000, 3.000], mean observation: 0.165 [-0.792, 1.007], loss: 5.514525, mean_absolute_error: 38.889011, mean_q: 50.738762\n",
      " 90900/100000: episode: 150, duration: 1.721s, episode steps: 437, steps per second: 254, episode reward: 175.431, mean reward: 0.401 [-17.253, 100.000], mean action: 1.465 [0.000, 3.000], mean observation: 0.071 [-0.844, 1.000], loss: 5.468071, mean_absolute_error: 39.000885, mean_q: 51.088081\n",
      " 91416/100000: episode: 151, duration: 2.109s, episode steps: 516, steps per second: 245, episode reward: 128.886, mean reward: 0.250 [-8.730, 100.000], mean action: 1.684 [0.000, 3.000], mean observation: 0.026 [-0.879, 1.000], loss: 6.329473, mean_absolute_error: 38.805779, mean_q: 50.951649\n",
      " 92095/100000: episode: 152, duration: 3.117s, episode steps: 679, steps per second: 218, episode reward: 141.524, mean reward: 0.208 [-18.758, 100.000], mean action: 1.455 [0.000, 3.000], mean observation: 0.118 [-0.592, 1.000], loss: 7.548132, mean_absolute_error: 38.757256, mean_q: 50.619041\n",
      " 92579/100000: episode: 153, duration: 1.942s, episode steps: 484, steps per second: 249, episode reward: 102.068, mean reward: 0.211 [-18.169, 100.000], mean action: 2.021 [0.000, 3.000], mean observation: 0.062 [-0.653, 1.000], loss: 6.496876, mean_absolute_error: 38.677872, mean_q: 50.312042\n",
      " 92922/100000: episode: 154, duration: 1.264s, episode steps: 343, steps per second: 271, episode reward: 131.513, mean reward: 0.383 [-19.627, 100.000], mean action: 1.274 [0.000, 3.000], mean observation: 0.021 [-0.617, 1.000], loss: 5.117312, mean_absolute_error: 38.474796, mean_q: 49.836098\n",
      " 93374/100000: episode: 155, duration: 1.696s, episode steps: 452, steps per second: 267, episode reward: 116.322, mean reward: 0.257 [-19.352, 100.000], mean action: 1.451 [0.000, 3.000], mean observation: 0.037 [-0.624, 1.000], loss: 5.187055, mean_absolute_error: 38.349205, mean_q: 49.785770\n",
      " 93818/100000: episode: 156, duration: 1.696s, episode steps: 444, steps per second: 262, episode reward: 169.550, mean reward: 0.382 [-14.138, 100.000], mean action: 1.403 [0.000, 3.000], mean observation: -0.008 [-0.691, 1.000], loss: 6.459397, mean_absolute_error: 38.026714, mean_q: 49.169643\n",
      " 94813/100000: episode: 157, duration: 4.543s, episode steps: 995, steps per second: 219, episode reward: 136.539, mean reward: 0.137 [-19.377, 100.000], mean action: 1.121 [0.000, 3.000], mean observation: 0.097 [-0.616, 1.000], loss: 6.317708, mean_absolute_error: 38.250870, mean_q: 49.453556\n",
      " 95327/100000: episode: 158, duration: 1.978s, episode steps: 514, steps per second: 260, episode reward: 135.583, mean reward: 0.264 [-19.702, 100.000], mean action: 1.798 [0.000, 3.000], mean observation: 0.060 [-0.795, 1.000], loss: 6.042405, mean_absolute_error: 37.871704, mean_q: 49.164776\n",
      " 95859/100000: episode: 159, duration: 2.184s, episode steps: 532, steps per second: 244, episode reward: 165.432, mean reward: 0.311 [-7.988, 100.000], mean action: 1.630 [0.000, 3.000], mean observation: 0.017 [-0.664, 1.000], loss: 4.917986, mean_absolute_error: 37.771095, mean_q: 48.698544\n",
      " 96267/100000: episode: 160, duration: 1.580s, episode steps: 408, steps per second: 258, episode reward: 193.879, mean reward: 0.475 [-17.631, 100.000], mean action: 1.164 [0.000, 3.000], mean observation: 0.080 [-0.655, 1.000], loss: 9.129398, mean_absolute_error: 37.862946, mean_q: 48.604004\n",
      " 96720/100000: episode: 161, duration: 1.758s, episode steps: 453, steps per second: 258, episode reward: 175.432, mean reward: 0.387 [-4.794, 100.000], mean action: 1.585 [0.000, 3.000], mean observation: 0.045 [-0.583, 1.000], loss: 6.304197, mean_absolute_error: 37.654240, mean_q: 49.031288\n",
      " 96805/100000: episode: 162, duration: 0.285s, episode steps: 85, steps per second: 299, episode reward: -142.819, mean reward: -1.680 [-100.000, 24.788], mean action: 0.718 [0.000, 3.000], mean observation: 0.112 [-1.892, 1.895], loss: 4.090473, mean_absolute_error: 37.281143, mean_q: 48.750988\n",
      " 97126/100000: episode: 163, duration: 1.184s, episode steps: 321, steps per second: 271, episode reward: 208.664, mean reward: 0.650 [-17.728, 100.000], mean action: 1.629 [0.000, 3.000], mean observation: 0.067 [-0.693, 1.011], loss: 5.068755, mean_absolute_error: 37.444195, mean_q: 48.477936\n",
      " 97502/100000: episode: 164, duration: 1.465s, episode steps: 376, steps per second: 257, episode reward: 181.193, mean reward: 0.482 [-9.853, 100.000], mean action: 1.269 [0.000, 3.000], mean observation: 0.103 [-0.560, 1.000], loss: 6.755285, mean_absolute_error: 37.667160, mean_q: 49.152344\n",
      " 97821/100000: episode: 165, duration: 1.185s, episode steps: 319, steps per second: 269, episode reward: 167.144, mean reward: 0.524 [-4.403, 100.000], mean action: 1.567 [0.000, 3.000], mean observation: 0.055 [-0.596, 1.000], loss: 5.286702, mean_absolute_error: 37.597462, mean_q: 48.856094\n",
      " 98431/100000: episode: 166, duration: 2.454s, episode steps: 610, steps per second: 249, episode reward: -276.197, mean reward: -0.453 [-100.000, 20.290], mean action: 1.893 [0.000, 3.000], mean observation: 0.046 [-0.764, 2.079], loss: 5.625789, mean_absolute_error: 37.858223, mean_q: 49.325657\n",
      " 98851/100000: episode: 167, duration: 1.683s, episode steps: 420, steps per second: 250, episode reward: 131.735, mean reward: 0.314 [-8.812, 100.000], mean action: 1.550 [0.000, 3.000], mean observation: 0.037 [-0.828, 1.000], loss: 5.489151, mean_absolute_error: 37.922443, mean_q: 49.110294\n",
      " 99253/100000: episode: 168, duration: 1.557s, episode steps: 402, steps per second: 258, episode reward: 150.105, mean reward: 0.373 [-12.885, 100.000], mean action: 1.326 [0.000, 3.000], mean observation: 0.079 [-0.885, 1.000], loss: 5.532248, mean_absolute_error: 37.927307, mean_q: 49.464478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 443.065 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f6dde48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "dqn.fit(env, nb_steps=100000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "# dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "dqn.load_weights('dqn_{}_weights.h5f'.format(ENV_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Redirect stdout to capture test results\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = mystdout = io.StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12224eeb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our algorithm for a few episodes.\n",
    "dqn.test(env, nb_episodes=200, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset stdout\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_text = mystdout.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "Testing for 200 episodes ...\n",
      "Episode 1: reward: 178.699, steps: 603\n",
      "Episode 2: reward: 156.761, steps: 436\n",
      "Episode 3: reward: 202.729, steps: 420\n",
      "Episode 4: reward: 137.160, steps: 566\n",
      "Episode 5: reward: 129.569, steps: 507\n",
      "Episode 6: reward: 161.740, steps: 692\n",
      "Episode 7: reward: 87.896, steps: 991\n",
      "Episode 8: reward: 113.709, steps: 863\n",
      "Episode 9: reward: 140.228, steps: 847\n",
      "Episode 10: reward: 156.817, steps: 543\n",
      "Episode 11: reward: 177.192, steps: 434\n",
      "Episode 12: reward: 67.031, steps: 1000\n",
      "Episode 13: reward: -151.882, steps: 241\n",
      "Episode 14: reward: 115.743, steps: 821\n",
      "Episode 15: reward: -422.611, steps: 772\n",
      "Episode 16: reward: 134.150, steps: 647\n",
      "Episode 17: reward: 178.546, steps: 518\n",
      "Episode 18: reward: 183.691, steps: 576\n",
      "Episode 19: reward: 136.796, steps: 516\n",
      "Episode 20: reward: 72.357, steps: 1000\n",
      "Episode 21: reward: -43.165, steps: 344\n",
      "Episode 22: reward: 138.292, steps: 828\n",
      "Episode 23: reward: 161.726, steps: 777\n",
      "Episode 24: reward: 175.101, steps: 514\n",
      "Episode 25: reward: 180.534, steps: 556\n",
      "Episode 26: reward: 77.979, steps: 471\n",
      "Episode 27: reward: 231.800, steps: 279\n",
      "Episode 28: reward: 28.704, steps: 1000\n",
      "Episode 29: reward: 140.056, steps: 824\n",
      "Episode 30: reward: 112.600, steps: 651\n",
      "Episode 31: reward: 148.378, steps: 842\n",
      "Episode 32: reward: 121.878, steps: 828\n",
      "Episode 33: reward: 146.463, steps: 626\n",
      "Episode 34: reward: 150.137, steps: 475\n",
      "Episode 35: reward: 133.317, steps: 898\n",
      "Episode 36: reward: -29.534, steps: 1000\n",
      "Episode 37: reward: 118.071, steps: 532\n",
      "Episode 38: reward: -246.507, steps: 358\n",
      "Episode 39: reward: 135.039, steps: 891\n",
      "Episode 40: reward: 227.467, steps: 428\n",
      "Episode 41: reward: 127.821, steps: 982\n",
      "Episode 42: reward: 138.060, steps: 330\n",
      "Episode 43: reward: 125.338, steps: 579\n",
      "Episode 44: reward: 0.470, steps: 1000\n",
      "Episode 45: reward: 29.845, steps: 1000\n",
      "Episode 46: reward: 210.027, steps: 753\n",
      "Episode 47: reward: 18.812, steps: 1000\n",
      "Episode 48: reward: 121.203, steps: 644\n",
      "Episode 49: reward: 133.563, steps: 621\n",
      "Episode 50: reward: 206.051, steps: 274\n",
      "Episode 51: reward: 91.107, steps: 662\n",
      "Episode 52: reward: 149.884, steps: 338\n",
      "Episode 53: reward: 113.566, steps: 730\n",
      "Episode 54: reward: 82.187, steps: 524\n",
      "Episode 55: reward: 118.789, steps: 545\n",
      "Episode 56: reward: 154.106, steps: 640\n",
      "Episode 57: reward: 145.614, steps: 307\n",
      "Episode 58: reward: 134.102, steps: 548\n",
      "Episode 59: reward: 125.147, steps: 434\n",
      "Episode 60: reward: -171.551, steps: 569\n",
      "Episode 61: reward: 141.653, steps: 693\n",
      "Episode 62: reward: 155.336, steps: 573\n",
      "Episode 63: reward: 165.257, steps: 583\n",
      "Episode 64: reward: 155.216, steps: 566\n",
      "Episode 65: reward: 138.559, steps: 589\n",
      "Episode 66: reward: 24.270, steps: 1000\n",
      "Episode 67: reward: 125.979, steps: 387\n",
      "Episode 68: reward: 138.825, steps: 700\n",
      "Episode 69: reward: 110.683, steps: 804\n",
      "Episode 70: reward: 71.103, steps: 1000\n",
      "Episode 71: reward: 46.133, steps: 1000\n",
      "Episode 72: reward: 51.116, steps: 1000\n",
      "Episode 73: reward: 139.033, steps: 519\n",
      "Episode 74: reward: 139.524, steps: 333\n",
      "Episode 75: reward: 200.587, steps: 381\n",
      "Episode 76: reward: 125.184, steps: 653\n",
      "Episode 77: reward: -55.509, steps: 298\n",
      "Episode 78: reward: 151.006, steps: 685\n",
      "Episode 79: reward: 63.934, steps: 1000\n",
      "Episode 80: reward: 161.631, steps: 437\n",
      "Episode 81: reward: 186.172, steps: 487\n",
      "Episode 82: reward: 140.470, steps: 639\n",
      "Episode 83: reward: 162.519, steps: 622\n",
      "Episode 84: reward: 138.424, steps: 916\n",
      "Episode 85: reward: 122.799, steps: 418\n",
      "Episode 86: reward: 146.762, steps: 315\n",
      "Episode 87: reward: 175.628, steps: 339\n",
      "Episode 88: reward: 121.376, steps: 654\n",
      "Episode 89: reward: 41.353, steps: 1000\n",
      "Episode 90: reward: 29.204, steps: 1000\n",
      "Episode 91: reward: 89.925, steps: 572\n",
      "Episode 92: reward: 88.538, steps: 599\n",
      "Episode 93: reward: 129.410, steps: 675\n",
      "Episode 94: reward: 134.426, steps: 452\n",
      "Episode 95: reward: 134.116, steps: 713\n",
      "Episode 96: reward: 200.253, steps: 428\n",
      "Episode 97: reward: 47.397, steps: 1000\n",
      "Episode 98: reward: 139.856, steps: 593\n",
      "Episode 99: reward: 131.734, steps: 672\n",
      "Episode 100: reward: 117.993, steps: 348\n",
      "Episode 101: reward: 174.030, steps: 805\n",
      "Episode 102: reward: 156.776, steps: 954\n",
      "Episode 103: reward: 132.891, steps: 336\n",
      "Episode 104: reward: 162.715, steps: 837\n",
      "Episode 105: reward: 154.789, steps: 830\n",
      "Episode 106: reward: 128.657, steps: 523\n",
      "Episode 107: reward: 131.438, steps: 373\n",
      "Episode 108: reward: 137.950, steps: 663\n",
      "Episode 109: reward: 152.297, steps: 390\n",
      "Episode 110: reward: 3.454, steps: 1000\n",
      "Episode 111: reward: 201.027, steps: 729\n",
      "Episode 112: reward: 157.485, steps: 265\n",
      "Episode 113: reward: 175.448, steps: 634\n",
      "Episode 114: reward: 157.135, steps: 526\n",
      "Episode 115: reward: -130.082, steps: 572\n",
      "Episode 116: reward: 96.510, steps: 515\n",
      "Episode 117: reward: 185.575, steps: 685\n",
      "Episode 118: reward: 29.793, steps: 911\n",
      "Episode 119: reward: 99.276, steps: 986\n",
      "Episode 120: reward: 171.065, steps: 857\n",
      "Episode 121: reward: 172.043, steps: 729\n",
      "Episode 122: reward: 167.679, steps: 653\n",
      "Episode 123: reward: 117.485, steps: 586\n",
      "Episode 124: reward: 119.898, steps: 836\n",
      "Episode 125: reward: 160.164, steps: 363\n",
      "Episode 126: reward: 27.741, steps: 1000\n",
      "Episode 127: reward: 150.175, steps: 330\n",
      "Episode 128: reward: -306.814, steps: 570\n",
      "Episode 129: reward: 105.209, steps: 595\n",
      "Episode 130: reward: 128.105, steps: 962\n",
      "Episode 131: reward: 3.019, steps: 1000\n",
      "Episode 132: reward: 50.437, steps: 1000\n",
      "Episode 133: reward: 53.909, steps: 1000\n",
      "Episode 134: reward: 144.750, steps: 603\n",
      "Episode 135: reward: 184.450, steps: 746\n",
      "Episode 136: reward: 141.008, steps: 516\n",
      "Episode 137: reward: 141.321, steps: 890\n",
      "Episode 138: reward: 123.026, steps: 617\n",
      "Episode 139: reward: 124.727, steps: 563\n",
      "Episode 140: reward: 24.772, steps: 1000\n",
      "Episode 141: reward: 163.886, steps: 870\n",
      "Episode 142: reward: 142.994, steps: 284\n",
      "Episode 143: reward: 171.412, steps: 587\n",
      "Episode 144: reward: 93.773, steps: 478\n",
      "Episode 145: reward: 162.508, steps: 517\n",
      "Episode 146: reward: 198.018, steps: 281\n",
      "Episode 147: reward: 136.661, steps: 297\n",
      "Episode 148: reward: 181.086, steps: 572\n",
      "Episode 149: reward: 236.462, steps: 471\n",
      "Episode 150: reward: 206.939, steps: 306\n",
      "Episode 151: reward: -3.956, steps: 1000\n",
      "Episode 152: reward: 177.818, steps: 584\n",
      "Episode 153: reward: -79.982, steps: 235\n",
      "Episode 154: reward: 135.112, steps: 963\n",
      "Episode 155: reward: 111.001, steps: 426\n",
      "Episode 156: reward: 144.492, steps: 652\n",
      "Episode 157: reward: 149.955, steps: 556\n",
      "Episode 158: reward: 178.367, steps: 388\n",
      "Episode 159: reward: 107.723, steps: 717\n",
      "Episode 160: reward: 170.858, steps: 655\n",
      "Episode 161: reward: 163.971, steps: 491\n",
      "Episode 162: reward: 150.346, steps: 328\n",
      "Episode 163: reward: 155.239, steps: 465\n",
      "Episode 164: reward: 47.301, steps: 1000\n",
      "Episode 165: reward: -61.290, steps: 366\n",
      "Episode 166: reward: 32.129, steps: 1000\n",
      "Episode 167: reward: 119.423, steps: 408\n",
      "Episode 168: reward: 137.238, steps: 935\n",
      "Episode 169: reward: -126.995, steps: 307\n",
      "Episode 170: reward: 147.522, steps: 355\n",
      "Episode 171: reward: 137.281, steps: 610\n",
      "Episode 172: reward: 170.908, steps: 513\n",
      "Episode 173: reward: 150.146, steps: 833\n",
      "Episode 174: reward: 23.497, steps: 1000\n",
      "Episode 175: reward: 141.925, steps: 709\n",
      "Episode 176: reward: -105.141, steps: 207\n",
      "Episode 177: reward: 114.381, steps: 530\n",
      "Episode 178: reward: 161.950, steps: 904\n",
      "Episode 179: reward: 120.533, steps: 448\n",
      "Episode 180: reward: 98.035, steps: 493\n",
      "Episode 181: reward: 149.042, steps: 505\n",
      "Episode 182: reward: -223.100, steps: 433\n",
      "Episode 183: reward: 180.435, steps: 410\n",
      "Episode 184: reward: 152.613, steps: 890\n",
      "Episode 185: reward: 124.880, steps: 398\n",
      "Episode 186: reward: 150.685, steps: 754\n",
      "Episode 187: reward: 47.198, steps: 1000\n",
      "Episode 188: reward: 131.109, steps: 344\n",
      "Episode 189: reward: 150.345, steps: 446\n",
      "Episode 190: reward: 168.015, steps: 845\n",
      "Episode 191: reward: 121.811, steps: 345\n",
      "Episode 192: reward: 158.802, steps: 533\n",
      "Episode 193: reward: 167.258, steps: 782\n",
      "Episode 194: reward: 146.215, steps: 631\n",
      "Episode 195: reward: 66.777, steps: 760\n",
      "Episode 196: reward: 144.925, steps: 609\n",
      "Episode 197: reward: 143.745, steps: 804\n",
      "Episode 198: reward: 168.867, steps: 584\n",
      "Episode 199: reward: 52.890, steps: 1000\n",
      "Episode 200: reward: 141.975, steps: 647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results text\n",
    "print(\"results\")\n",
    "print(results_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extact a rewards list from the results\n",
    "total_rewards = list()\n",
    "for idx, line in enumerate(results_text.split('\\n')):\n",
    "    if idx > 0 and len(line) > 1:\n",
    "        reward = float(line.split(':')[2].split(',')[0].strip())\n",
    "        total_rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rewards [178.699, 156.761, 202.729, 137.16, 129.569, 161.74, 87.896, 113.709, 140.228, 156.817, 177.192, 67.031, -151.882, 115.743, -422.611, 134.15, 178.546, 183.691, 136.796, 72.357, -43.165, 138.292, 161.726, 175.101, 180.534, 77.979, 231.8, 28.704, 140.056, 112.6, 148.378, 121.878, 146.463, 150.137, 133.317, -29.534, 118.071, -246.507, 135.039, 227.467, 127.821, 138.06, 125.338, 0.47, 29.845, 210.027, 18.812, 121.203, 133.563, 206.051, 91.107, 149.884, 113.566, 82.187, 118.789, 154.106, 145.614, 134.102, 125.147, -171.551, 141.653, 155.336, 165.257, 155.216, 138.559, 24.27, 125.979, 138.825, 110.683, 71.103, 46.133, 51.116, 139.033, 139.524, 200.587, 125.184, -55.509, 151.006, 63.934, 161.631, 186.172, 140.47, 162.519, 138.424, 122.799, 146.762, 175.628, 121.376, 41.353, 29.204, 89.925, 88.538, 129.41, 134.426, 134.116, 200.253, 47.397, 139.856, 131.734, 117.993, 174.03, 156.776, 132.891, 162.715, 154.789, 128.657, 131.438, 137.95, 152.297, 3.454, 201.027, 157.485, 175.448, 157.135, -130.082, 96.51, 185.575, 29.793, 99.276, 171.065, 172.043, 167.679, 117.485, 119.898, 160.164, 27.741, 150.175, -306.814, 105.209, 128.105, 3.019, 50.437, 53.909, 144.75, 184.45, 141.008, 141.321, 123.026, 124.727, 24.772, 163.886, 142.994, 171.412, 93.773, 162.508, 198.018, 136.661, 181.086, 236.462, 206.939, -3.956, 177.818, -79.982, 135.112, 111.001, 144.492, 149.955, 178.367, 107.723, 170.858, 163.971, 150.346, 155.239, 47.301, -61.29, 32.129, 119.423, 137.238, -126.995, 147.522, 137.281, 170.908, 150.146, 23.497, 141.925, -105.141, 114.381, 161.95, 120.533, 98.035, 149.042, -223.1, 180.435, 152.613, 124.88, 150.685, 47.198, 131.109, 150.345, 168.015, 121.811, 158.802, 167.258, 146.215, 66.777, 144.925, 143.745, 168.867, 52.89, 141.975]\n",
      "average total reward 110.330095\n"
     ]
    }
   ],
   "source": [
    "# Print rewards and average\n",
    "print(\"total rewards\", total_rewards)\n",
    "print(\"average total reward\", np.mean(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write total rewards to file\n",
    "f = open(\"lunarlander_rl_rewards.csv\",'w')\n",
    "wr = csv.writer(f)\n",
    "for r in total_rewards:\n",
    "     wr.writerow([r,])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment compares the performance of models that are trained by different methods (machine learning algorithm, deep learning algorithm and reinforcement learning algorithm). After conducting various experiments, it can be concluded that reinforcement learning model performs best on lunar lander, which gets the highest reward score.\n",
    "\n",
    "Machine learning using algorithms to parse data, learn from it, and then use this model to make a determination or prediction. and deep learning achieves great power and flexibility by learning to represent the world as nested hierarchy, While, reinforcement learning is to seek iteratively maximize a certain notion of a numerical reward obtained through continued interaction with its environment. In short, the process of reinforcement learning can be concluded that attempt, make mistakes, learn and master.\n",
    "\n",
    "In general, deep learning algorithm should perform better than traditional machine learning algorithm because it optimizes the features that are extracted, it also learns the feature extraction part, but in this experiment gets an unexpected result(machine learning model is better) due to the small size of training data, deep learning algorithm model should be trained by large number of data, which may cost a lot of time. In traditional machine learning part, I try to compare three algorithms (KNN, Neural Network and Random Forests), and their parameters are tuned by applying grid search strategy, the accuracy of Random Forests is the highest. In deep learning part. I conduct some experiments on adding the number of layers and pooling layer, but the accuracy still remains a low value.I try to increase the size of dataset. Correspondingly, accuracy and execution time are increased. Reinforcement learning is better than deep learning, because their mechanisms are different, reinforcement learning is to take action in an environment so as to maximize some notion of cumulative reward, but deep learning is to seek to iteratively minimize a certain loss function. Dynamical learning mechanism helps reinforcement learning model perform better after training.\n",
    "\n",
    "Expected Performance: Reinforcement Learning > Deep Learning > Machine Learning\n",
    "\n",
    "Actual Performance: Reinforcement Learning > Machine Learning > Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
